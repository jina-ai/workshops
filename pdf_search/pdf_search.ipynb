{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui5pz-xNNoAR"
      },
      "source": [
        "# Searching PDFs with Python, Transformers and Machine Learning\n",
        "\n",
        "Have you ever been searching through a stack of files and just can't find the right keywords to get what you're looking for? Staring at a screen and wracking your brain at 3am for the right word ain't fun, take it from me.\n",
        "\n",
        "How about trying to search through a stack of PDFs? That gets even harder since all that nice plain text is wrapped up in [a gnarly format](https://forum.quartertothree.com/t/is-pdf-an-evil-format/58598). Good luck grepping those!\n",
        "\n",
        "In this notebook we're going to kill those two birds with one stone.\n",
        "\n",
        "We'll harness the power of AI to find things *similar* to the search query you input, and we'll show you how to deploy that search engine in real life for anyone to use.\n",
        "\n",
        "We're going to do this with open-source tools from the Jina ecosystem.\n",
        "\n",
        "## Taking our time to learn\n",
        "\n",
        "We're going to take our time in this notebook, so we can understand how each part of the indexing/search pipeline (aka Flow) does its thing and check on our Documents every step of the way to see what the Flow did to them. This will give us a proper understanding of what's happening, instead of doing lots of hand-waving and making it look like dark magic.\n",
        "\n",
        "We'll then see how this process would be performed more quickly by building the Flow \"all-in-one\", as you would often do when building in production.\n",
        "\n",
        "## Why Jina and [neural search](https://docs.jina.ai/get-started/neural-search/)? What's wrong with good old symbolic search?\n",
        "\n",
        "### Semantics semantics semantics!\n",
        "\n",
        "Instead of just pattern-matching, our search engine will *meaning*-match. So if we were to search `matrix`, our top results would be related to matrices, but we'd also get results for vectors, tensors, and other similar concepts. This is because we're using deep neural nets (DNNs) to arrange words in a vector space and compare their embeddings, and similar words have similar [embeddings](https://docarray.jina.ai/fundamentals/document/embedding/).\n",
        "\n",
        "### Less code to write\n",
        "\n",
        "We can also reduce the amount of code we need to write using Jina Hub. Instead of manually integrating [Transformers](https://hub.jina.ai/executor/u9pqs8eb) with our search engine, we can simply use a couple of lines of code to download it from [Jina Hub](https://hub.jina.ai), run it in Docker, or run it in a [sandbox](https://docs.jina.ai/how-to/sandbox/) on the cloud. And if we wanted to swap it out for something like [spaCy](https://hub.jina.ai/executor/u7h7cuh2)? Again, just a matter of changing a couple of lines of code.\n",
        "\n",
        "### Deployment made easy\n",
        "\n",
        "Also, tools like Jina take a lot of hassle out of the orchestration and scaling. We can easily add [sharding, replicas](https://docs.jina.ai/how-to/scale-out/?highlight=sharding), [Kubernetes integration](https://docs.jina.ai/how-to/kubernetes/), and so on. \n",
        "\n",
        "## Meet our ingredients\n",
        "\n",
        "### **[DocArray](https://docarray.jina.ai/)**\n",
        "\n",
        "DocArray is a library for nested, unstructured data in transit, including text, image, audio, video, 3D mesh, etc. It allows deep-learning engineers to efficiently process, embed, search, recommend, store, and transfer the multi-modal data with a Pythonic API. ([star the repo]())\n",
        "\n",
        "###**[Jina](https://docs.jina.ai)**\n",
        " \n",
        " Jina is a framework that empowers anyone to build cross-modal and multi-modal[*] applications on the cloud. It uplifts a PoC into a production-ready service. Jina handles the infrastructure complexity, making advanced solution engineering and cloud-native technologies accessible to every developer. ([star the repo]())\n",
        "\n",
        "### **[Jina Hub](https://hub.jina.ai)**\n",
        "\n",
        "Download pre-built building blocks for neural search.\n",
        "\n",
        "## Without further ado...\n",
        "\n",
        "Let's start by downloading our data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGgYFyepOchY"
      },
      "source": [
        "## Downloading our data\n",
        "\n",
        "We're going to use simple text PDFs, with text taken from two Wikipedia pages ([Rabbit](https://en.wikipedia.org/wiki/Rabbit) and [Tiger](https://de.wikipedia.org/wiki/Tiger)). \n",
        "\n",
        "Of course, this is just a toy dataset. PDFs can differ in many ways, and depending on your use case you may need to process them very differently (e.g. OCR, image processing). Since ours are simple plain text, these steps will apply to most PDF search engines you may wish to build."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1y9HT-Rddsfy"
      },
      "outputs": [],
      "source": [
        "# Get data\n",
        "!mkdir data\n",
        "!wget -q --directory-prefix ./data https://github.com/jina-ai/workshops/raw/main/pdf_search/data/rabbit.pdf\n",
        "!wget -q --directory-prefix ./data https://github.com/jina-ai/workshops/raw/main/pdf_search/data/tiger.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2vbvTJQOyCr"
      },
      "source": [
        "## Installing DocArray\n",
        "\n",
        "DocArray is a library for nested, unstructured data in transit, including text, image, audio, video, 3D mesh, etc. It allows deep-learning engineers to efficiently process, embed, search, recommend, store, and transfer the multi-modal data with a Pythonic API.\n",
        "\n",
        "We'll use Jina to build our search pipeline (a.k.a [Flow](https://docs.jina.ai/fundamentals/flow/)) in a while. Everything that goes in or out of Jina has to be in the form of a [Document](https://docarray.jina.ai/fundamentals/document/) or [DocumentArray](https://docarray.jina.ai/fundamentals/documentarray/), provided by the DocArray package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgEs7M7ZdYt4"
      },
      "outputs": [],
      "source": [
        "!pip install -q docarray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osL261L3dhd2"
      },
      "outputs": [],
      "source": [
        "from docarray import DocumentArray"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZGCBbx2PF9S"
      },
      "source": [
        "## Loading our PDF files\n",
        "\n",
        "DocArray includes a handy shortcut to [load every file matching a glob](https://docarray.jina.ai/fundamentals/documentarray/construct/#construct-from-local-files). We can then use the `.summary()` method to see an overview of the output.\n",
        "\n",
        "As we go through the process in this notebook we'll regularly check our summary to see what's happening with our Documents as they move through the Flow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AMszuh7iE0t"
      },
      "outputs": [],
      "source": [
        "docs = DocumentArray.from_files(\"data/*.pdf\", recursive=True)\n",
        "docs.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBgCsbkePQk_"
      },
      "source": [
        "### Loading to blobs\n",
        "\n",
        "Right now the Documents contain only the URIs to the PDF files (as well as some other very basic data), but not the PDF content itself. We'll [load those URIs into blobs](https://docarray.jina.ai/fundamentals/document/fluent-interface/#blobdata):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mt4kS0DdkxGf"
      },
      "outputs": [],
      "source": [
        "for doc in docs:\n",
        "  doc.load_uri_to_blob()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBTcCIBoEiWD"
      },
      "outputs": [],
      "source": [
        "docs.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UOQTWdyPkE1"
      },
      "source": [
        "## Installing Jina\n",
        "\n",
        "[Jina]() is a framework that empowers anyone to build cross-modal and multi-modalapplications on the cloud. It uplifts a PoC into a production-ready service. Jina handles the infrastructure complexity, making advanced solution engineering and cloud-native technologies accessible to every developer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JIlFO1g5owT"
      },
      "outputs": [],
      "source": [
        "!pip install -q jina # Let's silence some of the output with -q so we don't fill our notebook with junk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GfxgpWCQKMJ"
      },
      "source": [
        "## Creating an indexing Flow\n",
        "\n",
        "We'll use Jina to generate our indexing and searching [Flows](https://docs.jina.ai/fundamentals/flow/). Our Documents will pass through these when we're indexing or searching. \n",
        "\n",
        "\n",
        "A Flow is built out of [Executors](https://docs.jina.ai/fundamentals/executor/), each of which perform a single processing task on each Document. We'll use [Jina Hub]() to provide pre-made Executors, meaning we don't have to write so much code.\n",
        "\n",
        "We'll build our Flow step by step through this notebook to get a clear idea of what's happening.\n",
        "\n",
        "Let's start with an empty Flow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Q3vy-6xEoMP"
      },
      "outputs": [],
      "source": [
        "from jina import Flow\n",
        "\n",
        "flow = Flow()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's plot our Flow so we can see what we've got:"
      ],
      "metadata": {
        "id": "Wu0r2Mjnp8at"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flow.plot()"
      ],
      "metadata": {
        "id": "nFWWQBhKp7n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, right now it's just a gateway in and a gateway out. In the next few steps we'll build up the rest of our Flow."
      ],
      "metadata": {
        "id": "iZ32hfdOqGSO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3k5Sp4kD7jT"
      },
      "source": [
        "### Extract PDF data\n",
        "\n",
        "If we're going to search through files, we need to get them into a format that our encoder can understand. In our case, that's plain text.\n",
        "\n",
        "We'll use [PDFSegmenter](https://hub.jina.ai/executor/x9w7lcwg) to extract that from our PDF Documents and store the sections of text as [chunks](https://docarray.jina.ai/fundamentals/document/nested/).\n",
        "\n",
        "Let's pull it from Jina Hub, so we can save ourselves the hassle of manually integrating it into our Flow. This will be a common pattern throughout this tutorial.\n",
        "\n",
        "**Note:** PDFSegmenter also extracts images from PDFs. Since our PDFs are text-only that's not important for this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8C_PPwt5J11"
      },
      "outputs": [],
      "source": [
        "flow = flow.add(\n",
        "    uses=\"jinahub://PDFSegmenter\",\n",
        "    install_requirements=True,\n",
        "    name=\"segmenter\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flow.plot()"
      ],
      "metadata": {
        "id": "5b2dda3vexz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to run our Flow. Since we're building the indexing pipeline right now, let's run it with `flow.index()`:"
      ],
      "metadata": {
        "id": "12tPvKjtqKyK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubkTagMF5mYZ"
      },
      "outputs": [],
      "source": [
        "with flow:\n",
        "  docs = flow.index(docs, show_progress=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our Documents have been processed by the Flow, let's see what's changed:"
      ],
      "metadata": {
        "id": "UIessnTzqS9F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fh16M9H158j_"
      },
      "outputs": [],
      "source": [
        "docs.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, each Document now has \"chunks\", consisting of the text extracted from each PDF. We can look at the chunks in more detail:"
      ],
      "metadata": {
        "id": "kWIYUZRhqZ6S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjqZhDO3E0jg"
      },
      "outputs": [],
      "source": [
        "docs[\"@c\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The text in each chunk is pretty long:"
      ],
      "metadata": {
        "id": "DpWo245EwxGs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rO0QnzJqJlkZ"
      },
      "outputs": [],
      "source": [
        "docs[\"@c\"].texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3wrZPDWEHif"
      },
      "source": [
        "### Sentencize the chunks\n",
        "\n",
        "Those chunks of text are still pretty unwieldy. To get decent results we'll need to chop them up some more by cutting them into sentences, and store each sentence as a subchunk of the original chunk.\n",
        "\n",
        "We'll use [SpacySentencizer](https://hub.jina.ai/executor/197kj4fv) to do that. You'll see that we're traversing through chunks of Documents rather than the top-level Documents themselves. That's because PDFSegmenter stored the text it extracted as chunks. We do this with `{\"traversal_paths\": \"@c\"}`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6FEq3bJEO11"
      },
      "outputs": [],
      "source": [
        "flow = flow.add(\n",
        "    uses=\"jinahub://SpacySentencizer\",\n",
        "    uses_with={\"traversal_paths\": \"@c\"},\n",
        "    install_requirements=True,\n",
        "    name=\"sentencizer\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zIuDlHlE-Ad"
      },
      "outputs": [],
      "source": [
        "flow.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**⚙️ Tinker time**\n",
        "\n",
        "Why not use the vanilla [Sentencizer](https://hub.jina.ai/executor/c6focg47)? Because it cuts sentences based on punctuation (like `.`) rather than natural language processing.\n",
        "\n",
        "That means a sentence like \"J.R.R. Tolkien turned to p. 3 of the book\" would be considered as five sentences by vanilla Sentencizer but only one by SpacySentencizer!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "sZU-zuO1gnBL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once again, let's index and examine what we've got:"
      ],
      "metadata": {
        "id": "wSu4SMPsquHB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ix8DPem_FDBm"
      },
      "outputs": [],
      "source": [
        "with flow:\n",
        "  docs = flow.index(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hIPi7cRFKS7"
      },
      "outputs": [],
      "source": [
        "docs.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the structure of our first Document here, showing \n",
        "\n",
        "* The top-level Document\n",
        "* Chunks (extracted by PDFSegmenter)\n",
        "* Chunks-of-chunks (the sentences extracted by SpacySentencizer):"
      ],
      "metadata": {
        "id": "rPgbzFQNw9FV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWxbBZavIDZK"
      },
      "outputs": [],
      "source": [
        "docs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can burrow down to the chunks-of-chunks level. For each level of chunk you want to go down, you can add another `c` to `[\"@c\"]`. So:\n",
        "\n",
        "- Top-level Document\n",
        "  - `[\"@c\"]` - chunks\n",
        "    - `[\"@cc\"]` - chunks of chunks"
      ],
      "metadata": {
        "id": "HnAXcJRpqyHZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJ8dHdaKJNch"
      },
      "outputs": [],
      "source": [
        "docs[\"@cc\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9z1f8IVJB-T"
      },
      "outputs": [],
      "source": [
        "docs[\"@cc\"].texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5F_waOoQS-7"
      },
      "source": [
        "### Encode the text\n",
        "\n",
        "To be able to do nearest-neighbor search, we need to be able to compare sentences' meanings with each other. This is where our encoder comes in. It generates [vector embeddings](https://docarray.jina.ai/fundamentals/document/embedding/) based on the semantic meaning of each sentence.\n",
        "\n",
        "As you can see, we're specifying the traversal path to work on chunks-of-chunks (i.e. sentences) rather than higher-level chunks (i.e. big blocks of text)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fP-XywEDDKRo"
      },
      "outputs": [],
      "source": [
        "flow = flow.add(\n",
        "    uses=\"jinahub://TransformerTorchEncoder\",\n",
        "    uses_with={\"traversal_paths\": \"@cc\"},\n",
        "    install_requirements=True,\n",
        "    name=\"encoder\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2kV7I6tDR5L"
      },
      "outputs": [],
      "source": [
        "flow.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**⚙️ Tinker time**\n",
        "\n",
        "In our example we're using [TransformerTorchEncoder](https://hub.jina.ai/executor/u9pqs8eb) with the default model (`sentence-transformers/all-mpnet-base-v2`). You can specify your own model as follows:\n",
        "\n",
        "```python\n",
        "flow = flow.add(\n",
        "    uses=\"jinahub://TransformerTorchEncoder\",\n",
        "    uses_with={\n",
        "      \"traversal_paths\": \"@cc\",\n",
        "      \"pretrained_model_name_or_path\": \"hfl/chinese-macbert-base\" # Chinese language model\n",
        "      },\n",
        "    install_requirements=True,\n",
        "    name=\"encoder\",\n",
        "    )\n",
        "```\n",
        "\n",
        "To go even further, you could swap out Transformers for another Executor, like [spaCy](https://hub.jina.ai/executor/u7h7cuh2):\n",
        "\n",
        "```python\n",
        "flow = flow.add(\n",
        "    uses=\"jinahub://SpacyTextEncoder\",\n",
        "    uses_with={\n",
        "      \"traversal_paths\": \"@cc\",\n",
        "      \"model_name\": \"en_core_web_md\"\n",
        "      },\n",
        "    install_requirements=True,\n",
        "    name=\"encoder\",\n",
        "    )\n",
        "```\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "iQUBd1afdT0L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YH-yT5ifMTR_"
      },
      "outputs": [],
      "source": [
        "with flow:\n",
        "  docs = flow.index(docs, show_progress=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After running our Flow this time, we see each Sentence (at `[\"@cc\"]`) has an `embedding` attribute, storing its vector embedding. The shape of this embedding varies depending on the Executor and model we use to encode it. Here's the embedding representation of the first sentence (i.e. sub-chunk) of the first chunk of our first PDF file:"
      ],
      "metadata": {
        "id": "qFP3o6BpfwKh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRCpBjKjXyIo"
      },
      "outputs": [],
      "source": [
        "docs[0].chunks[0].chunks[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OMKn5hNXteM"
      },
      "source": [
        "### Index and store Documents\n",
        "\n",
        "Now it's time to store all that data (vector embeddings + other metadata) on disk. We'll do this with the [SimpleIndexer](https://hub.jina.ai/executor/zb38xlt4) Executor. It will store everything in a SQLite database on disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPNjT7QEDcNa"
      },
      "outputs": [],
      "source": [
        "flow = flow.add(\n",
        "    uses=\"jinahub://SimpleIndexer\",\n",
        "    uses_with={\"traversal_right\": \"@cc\"},  # search through sub-chunks\n",
        "    install_requirements=True,\n",
        "    name=\"indexer\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCLX7UxuLSyF"
      },
      "outputs": [],
      "source": [
        "flow.plot()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with flow:\n",
        "  docs = flow.index(docs, show_progress=True)"
      ],
      "metadata": {
        "id": "qGMlZLFftU10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you click the folder icon in the Colab sidebar you should now see the \"workspace\" folder where everything is stored:\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAVMAAADKCAYAAAAYVaNLAAAABHNCSVQICAgIfAhkiAAAABl0RVh0U29mdHdhcmUAZ25vbWUtc2NyZWVuc2hvdO8Dvz4AAAAudEVYdENyZWF0aW9uIFRpbWUATW9uIDE4IEp1bCAyMDIyIDExOjQ4OjQ5IEFNIENFU1R9IS9/AAAgAElEQVR4nO3df3Sb1Z3n8XfGYYTVM2LBsmHaPKYlIpZxabFoCUIpcco4yc4pURlcN8IYpnbYHhOHMc1iBw9NYkrdyIwXb+0khcTeFtcox023ldOZQ2LYmB9CB5g+TgGDgpWdg8Q2wXZg0RwUtJts9g9b/i3/fGxLyvd1js+Jn5/XSvLxfe69z73LLl68eBEhhBBz1tvby18sdSGEECIZSJgKIYQGJEyFEEIDEqZCCKEBCVMhhNCAhKkQQmhAwlQIITQgYSqEEBqQMBVCCA1ImAohhAYkTIUQQgMSpkIIoQEJUyGE0ICEqRBCaEDCVAghNLB8qQsghEhOgUCA7u7ueV0jNzeXzMxMjUq0sJbJ5NBCiIWwdetWzp07N69r6PV6mpqaZnx8IBDg0KFDlJeXo9frpzw2HA7T1NTE5s2b5x3Yvb29UjMVQmjP5/Nx7tw5bDYbNpst5nHBYBCXyxVzfzgcxufzYTabZ3Rfl8vFyZMnqauro7KyMmaghsNh6urqCAQCuFwuqqqqZnT9qUiYCiEWjNFonHEQamHbtm04nU4CgUDMQB0dpIqisG3bNk3uLR1QQoikodfrqaqqQlGU4UANh8PD+8cHaVVV1bTNATMlNVMhxJIxGo3Y7fZJ9/l8Pk6ePDnra0YDdXwNFViwIIWEDtMQ7Q+sZseLkUn2pVPc/jo1+oMU/aCJ/juctNVuIL27lrV3H0S37RjHHjYteomFEGNNFabAnMIUJg9UYMGCFOYYpo2NjQSDQSorKxkYGJjxD2w0GqdsjJ4bA8oNCoaUUZuWr0DRQ+jkH1H7Q0TefIe+CxtI1/jOQoj4NT5QgQULUphjmEZ76qJB6na7Z3ReVlaW9mGaksPW1jYKr5zsho/TErmN/q/ZyUmZZL8QIuktW7Zs0j9rbU5hWlVVRTAYxGw2Yzabp6ymL6nTbup/XIv/LoVNdXmTHhJ6t52mfzqI+40g/Rgw3bKRLf95O4U3GIaOiOA/Uk/tXjfeU/1wVQ7Wux6g+uFNmHSL9pMIIWZpfGcTMGUv/3zNqTc/MzNzAR7XF1/k7b2UFO7g4BsRTHfYKbwjB9RWdhSWcPD9oWNeraX0RwfxhhQ2fK+QvBV9eJ+poOjHXYSWtvhCiBgm67WfqpdfC3OqmYbDYcLhMEajUdPCzMkFL7V/dyethpFNOks5Lbs2YIh9FhCkfU8TaiSHLf+thfKcwWpm5MN2Khy1ND19lOL6DQTfVgleMFBY28aePB3Qj/d3Xgx5edNcXwixFKYa/jRZL/+SDo3atWsXZ8+eZffu3QSDQTwez4zOUxQFh8Mxl1tOKfRBDz2jN1zxKZP18Y/R7+V5NQIXejh432oOjt/f8w7BCxtQbrViSunBXVOG7v3vsnGNFctdm5AnfCHiz3TjSGMNm9IiUOcUpnq9nrNnzw5/v6Sv96dY2fNGjA6oqXzST+g8GO6opuH+nInh+IUVKCmgy62muUlH7b522vd00QoYVm1i+5NOim+USBViKrMZ7TPZubPV2Ng47fCn8YHa2Ni4dK+TVlVVDT/mJ2z76ZWGwcd0vYJ1jXVUmEYI9YMhfWSLsmE7+zdsJ9Lvx3vsIPVPtrNrawY5x6uxyCgBISYwm82kpqbi8Xhm/OQ6mdTU1Fm9jupwOHC5XGzbtm3K2mY0UBsbGzV7Wp5zzXQhxmktqvQ81uXq8B5rov5frVR/Y7AFtP/FXRSVH2fFY220FCn0HNpF7a8/xb53P4XXmsgrqqbvxXZ2vOLHHwLLbGvEQlwiampq5hWkwKwrapmZmTOuZUYDVStzCtNAIEAwGEzMGukwheJHt+Au3stBx+103WJhBR+ivuEnZLBSfOvgG1IG+uh5twuvfS1u6w0YQu/S5QWddR1WCVIhYpru7aZkM6cwdTqdnDt3jrS0tFkP2tfyN8F86XK30+ZSaPp5K+43vfgjOkzfKubxHdVsWjl4jLJ5P4d19dQ+7cb7wlEwKFgKatj+aDHK0hZfCBFH5jQ5dHNzMz6fj6qqqjh4nVQIIZZWb2+vzLQvhBDz1dvbK/OZCiGEFiRMhRBCAxKmQgihAQlTIYTQgISpEEJoQMJUCCE0IGEqhBAakDAVQggNSJgKIYQGJEyFEEIDEqZCCKEBCVMhhNCAhKkQQmhAwlQIITQgYSqEEBqQMBVCCA1ImAohhAYkTIUQQgMSpkIIoQEJUyGE0MCclnpOBj6fj5aWFgYGBqY8zmazUVpaukilEkIkqku2Ztrc3DxtkAJ4PB6am5sXoUQiHgQCAerq6giHw0tdFJFgLtma6dmzZwFoaWmJeUxJSQkwGKjAktRQVVWlo6ODQCAw6f54rTknarldLhcnT56krq6OyspK9Hr98L5AIEAwGBz+JWw0GlEUhczMzKUqrogjl2yYztZSBarL5RoO/sksZdBPJVHLvW3bNpxO53ANNRqoLpeLzs7OSc/R6/XYbDby8/MxGo2LXGIRL5ZdvHjx4lIXYilEa50zqZmOttg1qsnKMBdGo5HNmzdjsVg0ud50ErXcAOFwGKfTSTAYJDMzczhQm5ubh38JxGK327Hb7YtUUhEvent7pWY6W/Fao5rOwMAAHR0dixpKM6UoyvDj9MDAwJga7VKVe9myZQBjaqilpaXYbDbMZjMw2Inpdrs5efLk8HnR78vLy8c0EYjkJ2E6Bx6PZ9HDdKoa9EyUlJTEbL9caqWlpcPtjgMDA1RWVo7Zv5jlDofD1NXVjbnn6ECNBimA2WzGbDbjdrtxu93D230+36RtriK5XbK9+TPR0tIy4Utoy263j2mLNBqN5OfnL1l5XC7XpOE9vpd/dIDa7XaysrImHD86YEXykzAVSyYtLQ273U5mZiY+n294u91uJzU1ddHL4/P5Jm0TLS0tRVGUMYFqt9sZGBjA5XIBTNpO2tnZOebnEslNwnQSyTi2NB5r1tGmkvz8fLq7u4e36/V61q9fv+jliVWTtNlsVFVVAWNrqKObekY//o/W0dGhfUFFXJIwHScapB6PJ+ZQmHgXfcSsq6ujqamJzs7O4R5qp9O51MUDIDc3d0wAGY3GMbVCu91OWlraUhRtUnq9fri2PDpQHQ7HlOddooNlLkkSpqOMr5G6XK5ph8LEm87OTnbv3o3b7eazzz6jv78fl8vF7t27pxz3udjGh9CxY8dwu91j3jyaLqi0FmtIU/RRfXRteXwbaqzHeRkmdemYV29+IBCgo6MDVVWHt1ksFjZt2pRwb4XEerSPbrPZbItdpFmLtuEpijLcQz4wMEB3d/dwUMVDbc9ut48Z3O52u4eDvq6ubsl6wM1mM/n5+ROeSF544QXMZjN2u51wOIyqqpw9e3ZCL7/NZhvzyzc/Pz/m479IPnMO09G/mXNzc8nMzCQQCKCqKj6fj/Ly8oT6hxStWZSWlg4HaPTPPp8vIcI0+h9527Ztw2Hl8Xjirld59GcZDocJh8Mx23NVVaWpqWmxiobdbsfn8xEMBseUobOzk/z8fBwOBw6HY7jZZPw4VBj8zBVFkVrpJWZOYRodi3fx4kV27949phYaCARobGykqalpSWsZszV6QPbo2mhaWlrC/FLw+XxkZWWNqfXZbLYxw3bi4e/D4/EMB43b7Z4ydBa7mUWv11NVVUVjY+OYwfgul4vu7u7hYVDRTrLm5uYJgRod3hUPn7VYPHMK0+7u7uHezPGP85mZmTgcDpqamuju7k6IGl3UZKGZKEEai9FojLv3xd1uNzabjXA4jF6vjxk6Pp9vTC//YokG6mSD8WO1jY4OVKmRXprmFKbRWXNyc3Mn3R999S8QCCRUmMajtLQ0zp49O+277pWVlcM94gMDAxMCNPpWjsPhWJRB8dFyx1JXVwcMBtfoGuBo0cHziqJoX8AZsNvt2Gw2Ojs7efXVVzl37tykx6WmpqLX6ydMjiIuLQv6OmmizgkZT+MxHQ4Hbrd7TBveZDo6Oti8eTMej4empibKy8uHAzUQCHDo0CEg9i9ArU1X7pnMJQsjA/uXitFoHG4nHT8Fn6IoGI1GMjMzJ21DlUC9tMwpTKP/SWM9xkd79+O5Rz81NZVz587NaXajxewRt1gss5rkw+Fw4HK5xrxHPrpzbbEe+Wdb7kSQmZkZ8990tGkgGqiNjY3DA/3FpSFl9+7du2d7ktFo5Pjx47zzzjvccsstY34DDwwM8PTTT3Px4kVKS0u57LLLtCyvZlauXInP54v56BZLWlraoobSbK1cuRKbzYbRaOT06dPAYLuvw+FIunCLN5dddhmrV6/m1KlTOBwOrrjiiqUuklgkH3/88dznM/X5fDQ2NrJs2TJyc3MxGo3DYxrD4TBms5nNmzfHde1UCCG00NvbO7/JoaOvLY7ucc3KysLhcOB0Olm2bBmVlZUSqEKIpDbvMB0tEAhMGG8qgSqEuBT09vZq927+ZONNq6qquHjx4oTJdoUQItks6EQn4wM1UYdKCSHEdBZlQb3o+DwZwC+ESEaatpkKIcSlStM2UyGEuJRJmAohhAYkTIUQQgMLOtHJQurt7V3qIgghksD111+vyXUSNky1+gCEEEIL8pgvhBAakDAVQggNSJgKIYQGJEyFEEIDEqZCCKEBCVMhhNCAhKkQQmhAwlQIITQgYSqEEBqQMBVCCA1ImAohhAYkTIUQQgMJO9HJQvB4PHg8ngnbFUXB4XAsQYmEEIlCwnRIIBCgubl50n0+n49wOExpaekil0oIkSgkTIdMt3JqrFprlNlsprKyUutiCSEShLSZTiMtLW1Gx/l8Pnw+3wKXRggRryRMp2Cz2XjyySdliWohxLQkTGOw2WzDbaSlpaUSqEKIKUmYTmJ0kEZJoAohpiJhOk5mZiZr1qwhEAiM2R4IBFizZg2ZmZlLVDIhRDyTMB0nEAjgdDpxuVxjtrtcLpxO54SQnbl+up6pp/3tyOC3IZXWJw/i/WR+5RVCxAcJ08VyIchrrlbcb/YNfn/GS3tbO699uLTFEkJoQ8aZLpYUC9XHT4x8v2orR05sXbryCCE0JWEaQzAYpK6ubsz3QggRi4TpEL1eP+b7cDg860H4468hhLh0LLt48eLFpS5EvPB4PKiqOu2rpePp9XpsNhsWi2WBSiaEiGe9vb1zC1NVVTl06BBpaWlUVVVNe3xzczOqqnLPPffIWE0hRNLp7e2dW29+c3MziqLMKEhhcMC7xWKZMNxICCGSxZzC9Ny5cxMGr4fDYU6ePDlmHKbH42FgYAAAo9E468dnIYRIFJp0QEXnAh0YGODcuXM0NTXhdDoJBoPk5+fLxMpCiKSnSZhmZmZSU1NDZ2cnLpeLuro61qxZQ1ZWFkajUYtbCCFEXJt1mE71qK4oCgCpqank5+fHPF+GEAkhks2s2kwHBgZwuVykpqaSm5s7YX+0HXWysMzNzSU1NZWWlpbhdlQhhEgWs+6ACofDLFu2bNLAdLvdAJw8eXLSc5ctW4YMaxVCJKNZhanRaKS0tJRwODxmPaSBgQE8Hg+BQID8/Pzht4fq6uqGmwW6u7sJh8M4HA5pRxVCJJ1Z10zH10gbGxuprKzkueeeY9u2bWRlZQFQV1dHbm7uhOMlSEeEDpeQfXst6oWlLokQYr7m3Zufn59PZmYmNpsNvV6PxWLB4XAMv2KZSGKtQKooytIP7zrTStG6Viy/Pcb2G5a2KEKIieYdpmazGbPZPGZbrJ78eBYdKzsZn89HOByesJSJEEJEzSlMU1NTZ90jPzAwQGpq6lxuN6W+vj4yMjLmfZ3p3s6KVWuNMpvNVFZWTn2TM0ep3V5Lq9qH7to8ii2hMbsjpzqo/2kT7V4/Eb0J6/eqcT6Sx+e/KmDtEyoA3u9cR0fJYV56zBLz+PSUmf3MQgjtzOl10nvuuQdVVWPW5MZzOp34fD7uueeeudxuSocPH+ajjz7S/Lqz5fP5ppmyL8jBhypo/3wDDc8doW3HbfhfVYlEd0e81P6gCu+XymnrfJ1jTXYiv6mg6nf9KPe38V5nNRadia2/PcGxRy1THi+EWHxzqpnabLZZtYfOdEKUuWpoaKCiooKrr756Qe8zL+930P62QvFvq9lwA4AJ54PP07VvaP/yHIp/cYTylSbSdcCKLXz/liZ++ic/FFjRfUGHDkBnQJcCMNXx6UvyIwpxKUuKNaA++ugjGhoa4qKGGtO/9RLU3cDNWaO2LdeN/DnFQAYqTWV3svrmm8j+6k1UvRCBWD39sz1eCLGgkiJMIUECNeXy2PtCR9n5g1r8udUcfuUE771zAucGnXbHCyEWVNKEadz7yvWYwn78p2Psf/+PdIcs2O+3ougBInw+VZ/YbI8XQiyopAnTq6++Or7bTVdtwn5jDwf2tNMTihD5sIumVu9IB9QKhRUpKu37jqK+7aXjyTLqX4kQiQwdob8CHX30vKniPxOZ/nghxKJKijCN+yAFQGHLzxuwf7KXgptvYnXxASI5FgzR3dcUU/OTjdBRQUFhGQc+uI0H7rWQQYh+AEMe9xUpqHuKePCXPdMfL4RYVAm/oN6+ffu4++675x2k0bkE5qOysnLCCwxCiOTX29ub+Es9FxQUaDJoXwgh5iPhH/O1ClItJqyWSa+FuHQl/GO+ljweD6qqznrhv+ikLhaLZYFKJoSIZ729vRKmQggxX729vYn/mC+EEPFAwlQIITQgYSqEEBqQMBVCCA1ImAohhAYkTIUQQgMSpkIIoQEJUyGE0EDMMP3oR18Y/hJJ5kIXO27OpuxftL1s6HAJ2bfXosps/+ISlPATnWgp1gqkiqLgcDiWoERJ7EwrRetasfz2GNtvWOrCCDF/EqZDAoFAzNVWfT4f4XCY0tLSRS6VECJRJHybaV9fnybXmW5yE4/HQ0lJScyvmcyFGnq7lQr7arKvv47s2wrY0dYzMtN+qIf26iLW3pTNddmrWV+2F+8nQ/terOCm1WXUN5axfnU22V9dTUHNUfzvd7CrcC3Z2dnctK6Evd7Q0LXaKcleT8UTOyi4PZvs7JtY/8Co600sGWpLBXfelk129N4zmWH6zFFqi4buv7GMA2pozO7IqQ5qS9ZzU/Z1ZN+8npI9XfRfgGBLAdfdtgtvxM/e71zH2ifU6T8DIeJcwofp4cOH42IRPZ/Ph8/ni31AxEv9D2s59c3HOfzCS7Q9tALvEw9S640AIY5WF1Hrt1DT/jKv/8FJ3p+bqPhZ10jY9nfR1fcf2dN6hLbd6wgdquDO4mfB8RRH3C1szzlFfXUTPdH2yvN+vGdyqHGf4ERnA3l9TZT9uIPQJEUL/qqMktYIhfVHOOZ2Yv/sWcp2dkwzY3+Qgw9V0P75BhqeO0Lbjtvwv6qOlDfipfYHVXi/VE5b5+sca7IT+U0FVb/rR7m/jfc6q7HoTGz97QmOPWqZ2WcgRBxL+DAF4n9VUoBwkOAnBnLW5JFzrYJl8+M8VbeF29IAdFgeauPw09vJW5VO+so8iv8uh9C7PQSj5+s3UP7YJiyrTFgKtlJ4AxjWb6fmLgumVVaKSzegnPHTE03L5Qr20mJyrtShW5HH9kfs6Lp+z/Pja3oXVFqbe7A+4qTYakJZlcfWRwrJeOX3HJ8seaPe76D9bYXin1SzIddETl4xzgetDK+PujyH4l8coeWxTeSsSEexbuH7t0To+ZMfUnTovqAbPFZnQJcyw89AiDiWFG2m0WWe43odqCs38sD9rZSV344/byPr1mxk06ZiLEPzSaenR3D/rIgHX+oh+FkELkSIXGslEq1pLgfd8N/W5eguhysMhpHrL9ehI0LkPJAy8fY6Uw6mCyrB08Co0/i4h57TIbzbV5O9PboxQuR8Dv39444d7d96Cepu4OasUduWj1pqOsVABs9TX/Ywz/8pSCgSgUgEw/difUC6qT+DSX4mIeJJUtRMYSRQ47eGasC64wgv/3MD91l09P6mgvV/U0b7BwD9tG8v4cC/b2TPH17nvXfe4+Udo2p5Wjgfmfxx+QKwXKGw4QjHnj829PUSL73QQvGXp7lmyuWx94WOsvMHtfhzqzn8ygnee+cEzg1T/USL8BkIsYCSJkzj3vsd1D/VQd8KK5tKqmlob6P8qi5aO/xwQeW1N8BaUIwlfTA+Po9M9Yw9M5FR4z0jPe/gT1nB9SvGHZRuQjH0ETyjQ7lWGf7KuCYdw1S1wa9cjynsx386xv73/0h3yIL9fiuKHiDC51P18S3QZyDEYkmaMI375Z71n6I272TXz7vo+TCI/5WjvHZaR/qKDEhZyfVfDuFt20tXt4r30C4e3tdDJBKjNjkT54O4n6qn6/0gwe52dv3TUXR3fJ+88Y/tKVaK7zWhPvUwtUdUgh/66XqmhPWFe0c6syazahP2G3s4sKednlCEyIddNLV6R8q7QmFFikr7vqOob3vpeLKM+lciRCJDR+ivQEcfPW+q+M9EFuYzEGIRJUWYxn2QAqwopuEXD2B4sYqCdWu5s8qN7t4GnJsMgIktdTVY+56lrLCIit9EsD9YSM4XIoTmmiTL07Gs6ufAljtZe08t6pfLadi9YdIm0JxtLewvTcf7RBFr8wvY9UIGW39WTM6U7ZQKW37egP2TvRTcfBOriw8QybGMXP+aYmp+shE6KigoLOPAB7fxwL0WMggNjhIw5HFfkYK6p4gHf9mzMJ+BEIso5hpQo18jvfq/fLZoBZqtffv2cffdd887SH0+34zGik6lsrISs9k8r2toItROyeq9mJ57ierceVynu571xQcJjq+h6vJwvryfTbE6p4S4xPT29iZ+b35BQYFmyz2LcW54gLZ/LuTzCTsuJ0OCVIgx5hSmFz7+gAufBCZsv+yLX2NZ6hXzLtRsaBWkWqx5r8U14orOQPq1kppCzMSsH/MvfPwBA09MPjPF8i99jasefH7RA1UrHo8HVVWnfbV0PL1ej81mw2KxLFDJhBDxbE6P+efe/HXMfef/11ucrbeSclXmpPuXf/Hr/NV3nbO95aKx2WzYbLalLoYQIgHNuc10+Rdv5C9S/8PkOyep6/6/c/+b8MtN/OXKNehuvHOutxVCiLg05zD9q+8+yV+avjXj4/+P/xU+2beR//vntyRMhRBJJynGmQohxFKTMBVCCA1ImAohhAYkTIUQQgMSpkIIoQEJUyGE0MCch0ad//NbsGyWx4sFEuTg3etx5x3hyDbTUhdGiEvSrMM09Zv38tnRWv7995VzumHqN++d03mLwePx4PF4JmxXFAWHw7EEJRJCJIpZh2nKVddifOxdLnw8caKT6c/NJOWqa2d93mIIBAI0NzdPus/n8xEOhyktLV3kUgkhEsWcHvNTrro2bkKxr69Pk5mjppvcJFatNcpsNlNZGbu2rtaspaR/O683bUIH9LcVcfvTJtqO12BJAd6uZb3Dz5ZXWii8EvpfrGfnU+10nQphuNZK4SNOtt+RPnitJ9ZS1J1L4eVe2tUcnK/XjL3ZmaNUFFbw7h0tHN5lxdDvZe/OXTzb5SekU7DctZ2aHZsw6Yau9V4exXov7a/6iVxpwf6jPdQUmIbWX+rH+8xPqf91Fz2nIxhu2ED5E06Kbxxananfy96a2sFrL8/AUlDNnkc3oKQAhFBbdrLr4FH8nxhQ8u6j5vGtWNOn+csQIgElfAfU4cOH42IRPZ/Ph8/ni7k/59ZcUP+IegEghLdLJXLay/GTg/uDqkow6zasV0Kku56if+iA7zVwpPMIDYU62suLqO8emXI+8lY3feudHHbXjF2KJKxS/8MKvFk1ND9mxUCIjpoyDoTsNPzhJY7sL0Z3tIqHn/GPXOtPKmxu5vUTJzi8NZ3jP36QpneHytVWQVlziI3Ow7z8ymH+Meddah+qH/o5/BzcWsKzoY04//sxjuzfguFYBQ/+vGfw3F+VUdIaobD+CMfcTuyfPUvZzo7BmfaFSDIJH6ZAnK9KOkh3y7exhFXUU0DYy/94y8KGb31K10t+IEL3m36UW60ohOhqbqUvrxrn/VZMK0xYS5z84x19tP6ya3g9JN0tW3j8/jxyVikjS4WcP0X7P5RxkC3s/6+FQ7XDT+kLRsi4KQ/rSgWTdQvO+hoKb9SNKlsx5Xco6HQGcoqqKb8xSEfHYCBmrK2mrb2BLVYT6dfksOneDShneuj5GHjbTfvbOTxQu5W8VQomazHOHXZ0H/YQvKDS2tyD9REnxVYTyqo8tj5SSMYrv+e4rJMnklBShGn8L/MMXJnLulV+Xnuzn8gbx/Ga1rG9wErf8S6CEZU/vqXDuiYHLgR5xx/B9M1R6ylhINdiInLKTzC6SacbtwxyhOChnex6McKGHz6AZXieagX7D+3wqwLWFlVQ+0wHwa/YKc5TYhRUwZRloO+DU0QA3V9n0N+xk4J1q7npq9lkFx7Efx64ABG/n+CVOeT89cjZhr/dw+H6QpSPe+g5HeLo9tVkZ2cPfhXuxR/pp1+qpiIJJUWYQiIEqoLVaqLnDS/eV71krMnDtObbWE69Rpeqon5m5bavjxw96Xrx5ycuIDJa6LzChjuu4OiT9XhH1f7S/3YPx145Qs1d1xPpPkDJ36xnx9HYiRa5MNKc4H+mhLKOy7nv6U5OvPMe77VvwRRtaZ+qxf0CsFyhsOEIx54/NvT1Ei+90ELxl6f8MYRISEkTponA9C0LV7z5LAde0pG3xgQGK+u+ruJuOk7w67dh1QMpJr5q0tGjqozkYYhu1Y8u66vEqk+CDtO9e2io30Ph8nZ27OkaPD/cQ/uTB+mKmMgr2ErN/sPs/x64254fabs8P/o6fnp6ImRcuxIdIdQ3/WTcUcimVUP15FFLL+u+bEL5pAf/6ZGzI92t1D7TRX+6CcXQR/CMDuVaZfgr45p0DFOueipEYkqaME2I5Z5vXEduRMUbsbLuBoB0rGtNqF4V0xrr0GO9jry/LyTjxVp2tg2uY+/9VRX1L2ZQ+Pd5k9dYh+iWAwYr1T8rRve7KnYeDYEO+l+qp6rmIN5TQYLvdjF+d24AAAIGSURBVHH8rT4M14y0tUbePMjOQ4P36mrcxYH3TRRuygEMKF8yEPyXA7R2qagvtlLxaCvB8xEiEeBGO4U39tC0c+/gtf+1narKeryfpZOeYqX4XhPqUw9Te2To2s+UsL5wLz3jVzsVIgkkRZgmRJAC6Cx826Ij/dZ1w2vSK3kbydGZsN46UufUfaOa5voNhH5Zwvp1d1LxG9jU1Ex17lRROuo239jOU/8pg6M1Ozn6cQ5b9zZgj7RT9p21rC3ciXfFdvY/OhLMulUWMl7dxZ356ylzRdhY+xRbh5b5sv6oge1Zp6h/oICimue5wlHOppXw6ccAJrbsbeE+3fNUfGct6394kND6BvY9lANAzrYW9pem432iiLX5Bex6IYOtPyse/tmFSCazXlAv3uzbt4+777573kHq8/moq6ub1zUqKysxm83zusZiU59YS9H/3MrrLYXIOqRCzM2cFtSLNwUFBZot9yyEEHOV8I/5WgWpFmvea3ENIURiSvjHfC15PB5UVZ321dLx9Ho9NpsNi8WyQCUTQsSzpHjM15LNZsNmsy11MYQQCShmzVQIIcTM9Pb2Jn6bqRBCxAMJUyGE0ICEqRBCaEDCVAghNCBhKoQQGpAwFUIIDUiYCiGEBiRMhRBCAxKmQgihAQlTIYTQgISpEEJoQMJUCCE0IGEqhBAakDAVQggN/H9lnx/zTujtwAAAAABJRU5ErkJggg==)"
      ],
      "metadata": {
        "id": "e1ozToAWtWMb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux3DAxKCUHNf"
      },
      "source": [
        "## Building a more \"production-ready\" Flow\n",
        "\n",
        "Our Flow was built in a very scattered way since we stepped through everything step-by-step. In the real world you would typically create a Flow \"all-in-one\" like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlkogWJ4S1C1"
      },
      "outputs": [],
      "source": [
        "flow = (\n",
        "    Flow()\n",
        "    .add(\n",
        "        uses=\"jinahub://PDFSegmenter\",\n",
        "        install_requirements=True,\n",
        "        name=\"segmenter\"\n",
        "    )\n",
        "    .add(\n",
        "        uses=\"jinahub://SpacySentencizer\",\n",
        "        uses_with={\"traversal_paths\": \"@c\"},\n",
        "        install_requirements=True,\n",
        "        name=\"sentencizer\",\n",
        "    )\n",
        "    .add(\n",
        "        uses=\"jinahub://TransformerTorchEncoder\",\n",
        "        uses_with={\"traversal_paths\": \"@cc\"},\n",
        "        install_requirements=True,\n",
        "        name=\"encoder\"\n",
        "    )\n",
        "    .add(\n",
        "        uses=\"jinahub://SimpleIndexer\",\n",
        "        uses_with={\"traversal_right\": \"@cc\"},\n",
        "        install_requirements=True,\n",
        "        name=\"indexer\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPNVp5d_TW-r"
      },
      "outputs": [],
      "source": [
        "flow.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**⚙️ Tinker time**\n",
        "\n",
        "You can also build a Flow in YAML and import it using:\n",
        "\n",
        "```python\n",
        "flow = Flow().\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "l0T2s8fpwG0G"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REW6LCKbQX0b"
      },
      "source": [
        "## Indexing our Documents\n",
        "\n",
        "Now it's time to run the Flow.\n",
        "\n",
        "First we'll remove any old index data that may be lying around and start with our original DocumentArray to ensure nothing carried over:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbvROMahT6oR"
      },
      "outputs": [],
      "source": [
        "!rm -rf workspace\n",
        "docs = DocumentArray.from_files(\"data/*.pdf\", recursive=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now we'll run the Flow:"
      ],
      "metadata": {
        "id": "WFgzwBZlt7lF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcNUF796LxKb"
      },
      "outputs": [],
      "source": [
        "with flow:\n",
        "  docs = flow.index(docs, show_progress=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6RyADoBVASl"
      },
      "source": [
        "## Creating a search Flow\n",
        "\n",
        "Now that we've got our indexing Flow out of the way, let's build our search Flow.\n",
        "\n",
        "When a user searches, they'll submit just a simple text string, not a PDF. Therefore we can use a much simpler Flow since we don't need to worry about extracting and sentencizing the input query:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMt36HepU-s2"
      },
      "outputs": [],
      "source": [
        "search_flow = (\n",
        "    Flow()\n",
        "    .add(\n",
        "        uses=\"jinahub://TransformerTorchEncoder\", \n",
        "         name=\"encoder\"\n",
        "    )\n",
        "    .add(\n",
        "        uses=\"jinahub://SimpleIndexer\",\n",
        "        uses_with={\"traversal_right\": \"@cc\"},\n",
        "        name=\"indexer\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnPJnXbgWFyo"
      },
      "outputs": [],
      "source": [
        "search_flow.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we're going to search our index, we'll need a search term, which we'll specify here.\n",
        "\n",
        "As you might have noticed, everything going into (and coming out of) Jina is a Document or DocumentArray. That means we'll need to wrap our search term into a Document as well:"
      ],
      "metadata": {
        "id": "FYpJwrKzmGkR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeWUqFoaUqb1"
      },
      "outputs": [],
      "source": [
        "search_term = \"where does a snow leopard live?\"\n",
        "\n",
        "from docarray import Document\n",
        "\n",
        "query_doc = Document(text=search_term)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qo-PlDr-L6cS",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "with search_flow:\n",
        "  results = search_flow.search(query_doc, show_progress=True, return_results=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at those results and see the score assigned to each match. Since we're using cosine similarity, a lower score means a better match:"
      ],
      "metadata": {
        "id": "XX6IwL4HsB2O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Csa9IUcpU2I-"
      },
      "outputs": [],
      "source": [
        "for match in results[0].matches:\n",
        "  print(match.text)\n",
        "  print(match.scores[\"cosine\"].value)\n",
        "  print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting it into production\n",
        "\n",
        "Colab notebooks have a number of restrictions that make real-world stuff quite difficult. If we were building this outside of a notebook, we could:\n",
        "\n",
        "* Set up a [RESTful or gRPC gateway](https://docs.jina.ai/fundamentals/gateway/) and keep the Flow open to requests using `flow.block()`\n",
        "* Use [sharding and replicas](https://docs.jina.ai/how-to/scale-out/) to improve performance and reliability.\n",
        "* [Monitor our Flow with Grafana](https://docs.jina.ai/fundamentals/flow/monitoring-flow/)\n",
        "* Better yet, host our Flow on [JCloud](https://docs.jina.ai/fundamentals/jcloud/), so we don't have to use any of our own compute for encoding, indexing, hosting, etc (encoding is especially hungry on the hardware)\n",
        "* Finetune our results using [Finetuner](https://finetuner.jina.ai) to provide better matches\n",
        "* Use a more specialized model (rather than just general purpose)"
      ],
      "metadata": {
        "id": "xVQ-AHbSuZRi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learn more\n",
        "\n",
        "Want to dig more into the Jina ecosystem? Here are some resources:\n",
        "\n",
        "- [Developer portal](https://learn.jina.ai) - tutorials, courses, videos on using Jina\n",
        "- [Fashion search notebook](https://colab.research.google.com/github/alexcg1/neural-search-notebooks/blob/main/fashion-search/1_build_basic_search/basic_search.ipynb) - build an image-to-image fashion search engine\n",
        "- [DALL-E Flow](https://colab.research.google.com/github/jina-ai/dalle-flow/blob/main/client.ipynb#scrollTo=NeWDy9viOCAP)/[Disco Art](https://colab.research.google.com/github/jina-ai/discoart/blob/main/discoart.ipynb#scrollTo=47428f37) - create AI-generated art in your browser"
      ],
      "metadata": {
        "id": "ktOVGnmKuRx2"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "pdf_search.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}