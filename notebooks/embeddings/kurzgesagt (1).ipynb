{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Dependencies"
      ],
      "metadata": {
        "id": "qt3nai8YENmY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVSBQ3JSiHR-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef563840-6c61-441b-9c2c-f4c3b8a45f13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: sagemaker in /usr/local/lib/python3.10/dist-packages (2.212.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: jina-sagemaker in /usr/local/lib/python3.10/dist-packages (0.0.21)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: attrs<24,>=23.1.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (23.2.0)\n",
            "Requirement already satisfied: boto3<2.0,>=1.33.3 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (1.34.59)\n",
            "Requirement already satisfied: cloudpickle==2.2.1 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (2.2.1)\n",
            "Requirement already satisfied: google-pasta in /usr/local/lib/python3.10/dist-packages (from sagemaker) (0.2.0)\n",
            "Requirement already satisfied: protobuf<5.0,>=3.12 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (3.20.3)\n",
            "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (6.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (23.2)\n",
            "Requirement already satisfied: pathos in /usr/local/lib/python3.10/dist-packages (from sagemaker) (0.3.2)\n",
            "Requirement already satisfied: schema in /usr/local/lib/python3.10/dist-packages (from sagemaker) (0.7.5)\n",
            "Requirement already satisfied: PyYAML~=6.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (6.0.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from sagemaker) (4.19.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from sagemaker) (4.2.0)\n",
            "Requirement already satisfied: tblib<3,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (2.0.0)\n",
            "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (2.0.7)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.10/dist-packages (from sagemaker) (7.0.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from sagemaker) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.59 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0,>=1.33.3->sagemaker) (1.34.59)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0,>=1.33.3->sagemaker) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0,>=1.33.3->sagemaker) (0.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.17.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker) (0.18.0)\n",
            "Requirement already satisfied: ppft>=1.7.6.8 in /usr/local/lib/python3.10/dist-packages (from pathos->sagemaker) (1.7.6.8)\n",
            "Requirement already satisfied: dill>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from pathos->sagemaker) (0.3.8)\n",
            "Requirement already satisfied: pox>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from pathos->sagemaker) (0.3.4)\n",
            "Requirement already satisfied: multiprocess>=0.70.16 in /usr/local/lib/python3.10/dist-packages (from pathos->sagemaker) (0.70.16)\n",
            "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.10/dist-packages (from schema->sagemaker) (21.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy faiss-cpu sagemaker requests jina-sagemaker tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up Jina Embeddings v2 on Sagemaker Jumpstart"
      ],
      "metadata": {
        "id": "fwysaiFRRE-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies and configure AWS CLI"
      ],
      "metadata": {
        "id": "AYVZlnmWt84Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aws configure\n",
        "!pip install awscli"
      ],
      "metadata": {
        "id": "ewBIrG7BSPZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12090e38-d36f-41b6-c7f5-69551012a1a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aws in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Requirement already satisfied: configure in /usr/local/lib/python3.10/dist-packages (0.5)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.10/dist-packages (from aws) (2.49.0)\n",
            "Requirement already satisfied: fabric>=1.6 in /usr/local/lib/python3.10/dist-packages (from aws) (3.2.2)\n",
            "Requirement already satisfied: prettytable>=0.7 in /usr/local/lib/python3.10/dist-packages (from aws) (3.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from configure) (6.0.1)\n",
            "Requirement already satisfied: invoke>=2.0 in /usr/local/lib/python3.10/dist-packages (from fabric>=1.6->aws) (2.2.0)\n",
            "Requirement already satisfied: paramiko>=2.4 in /usr/local/lib/python3.10/dist-packages (from fabric>=1.6->aws) (3.4.0)\n",
            "Requirement already satisfied: decorator>=5 in /usr/local/lib/python3.10/dist-packages (from fabric>=1.6->aws) (5.1.1)\n",
            "Requirement already satisfied: deprecated>=1.2 in /usr/local/lib/python3.10/dist-packages (from fabric>=1.6->aws) (1.2.14)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable>=0.7->aws) (0.2.13)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2->fabric>=1.6->aws) (1.14.1)\n",
            "Requirement already satisfied: bcrypt>=3.2 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.4->fabric>=1.6->aws) (4.1.2)\n",
            "Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.4->fabric>=1.6->aws) (42.0.5)\n",
            "Requirement already satisfied: pynacl>=1.5 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.4->fabric>=1.6->aws) (1.5.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3->paramiko>=2.4->fabric>=1.6->aws) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4->fabric>=1.6->aws) (2.21)\n",
            "Requirement already satisfied: awscli in /usr/local/lib/python3.10/dist-packages (1.32.59)\n",
            "Requirement already satisfied: botocore==1.34.59 in /usr/local/lib/python3.10/dist-packages (from awscli) (1.34.59)\n",
            "Requirement already satisfied: docutils<0.17,>=0.10 in /usr/local/lib/python3.10/dist-packages (from awscli) (0.16)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from awscli) (0.10.0)\n",
            "Requirement already satisfied: PyYAML<6.1,>=3.10 in /usr/local/lib/python3.10/dist-packages (from awscli) (6.0.1)\n",
            "Requirement already satisfied: colorama<0.4.5,>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from awscli) (0.4.4)\n",
            "Requirement already satisfied: rsa<4.8,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from awscli) (4.7.2)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from botocore==1.34.59->awscli) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore==1.34.59->awscli) (2.8.2)\n",
            "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore==1.34.59->awscli) (2.0.7)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.5.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.34.59->awscli) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!aws configure"
      ],
      "metadata": {
        "id": "ucwSSF2oS8lT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbe35a58-30fb-48cf-a358-f6759651f6e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AWS Access Key ID [****************ZSFA]: \n",
            "AWS Secret Access Key [****************Giia]: \n",
            "Default region name [us-east-1]: \n",
            "Default output format [JSON]: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "role = \"arn:aws:iam::253352124568:role/service-role/AmazonSageMaker-ExecutionRole-20230527T104084\"\n",
        "\n",
        "import boto3\n",
        "\n",
        "#role = boto3.Session().role\n",
        "region = boto3.Session().region_name"
      ],
      "metadata": {
        "id": "Rji2nLwj4kBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to Jina Embeddings v2 Endpoint on Sagemaker\n",
        "\n",
        "To have this working you should have first already created an endpoint for inference, by\n",
        "1. Subscribing to [_Jina Embeddings v2 Base - en_](https://aws.amazon.com/marketplace/pp/prodview-5iljbegvoi66w) package on AWS marketplace.\n",
        "2. Creating a [Sagemaker Endpoint](https://us-east-1.console.aws.amazon.com/sagemaker/home?region=us-east-1#/endpoints) for inference using the subscribed model.\n",
        "\n",
        "Once an endpoint is created, continue running the code-blocks below to deploy the created endpoints, and run inference."
      ],
      "metadata": {
        "id": "GJV5o5W6uE4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the name of the model that you subscribed to\n",
        "subscribed_model_name = \"jina-embeddings-v2-base-en\""
      ],
      "metadata": {
        "id": "j4in-3gdZv7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping for Model Package Names\n",
        "model_name_map = {\n",
        "    \"jina-embeddings-v2-base-en\": \"jina-embeddings-v2-base-en-32555da8a0b431d190bf3eca46758b72\",\n",
        "    \"jina-embeddings-v2-small-en\": \"jina-embeddings-v2-small-en-0e950fb984e3396fa4e1108adf69937c\",\n",
        "    \"jina-embeddings-v2-base-de\": \"jina-embeddings-v2-base-de-c269d166764133348365f57b8f1d8c7a\",\n",
        "    \"jina-embeddings-v2-base-zh\": \"jina-embeddings-v2-base-zh-4da30f467aaf347580ba5ed2648e399a\",\n",
        "}\n",
        "\n",
        "# Specify the model name\n",
        "model_name = model_name_map[subscribed_model_name]\n",
        "\n",
        "# Mapping for Model Packages\n",
        "model_package_map = {\n",
        "    \"us-east-1\": f\"arn:aws:sagemaker:us-east-1:253352124568:model-package/{model_name}\",\n",
        "    \"us-east-2\": f\"arn:aws:sagemaker:us-east-2:057799348421:model-package/{model_name}\",\n",
        "    \"us-west-1\": f\"arn:aws:sagemaker:us-west-1:382657785993:model-package/{model_name}\",\n",
        "    \"us-west-2\": f\"arn:aws:sagemaker:us-west-2:594846645681:model-package/{model_name}\",\n",
        "    \"ca-central-1\": f\"arn:aws:sagemaker:ca-central-1:470592106596:model-package/{model_name}\",\n",
        "    \"eu-central-1\": f\"arn:aws:sagemaker:eu-central-1:446921602837:model-package/{model_name}\",\n",
        "    \"eu-west-1\": f\"arn:aws:sagemaker:eu-west-1:985815980388:model-package/{model_name}\",\n",
        "    \"eu-west-2\": f\"arn:aws:sagemaker:eu-west-2:856760150666:model-package/{model_name}\",\n",
        "    \"eu-west-3\": f\"arn:aws:sagemaker:eu-west-3:843114510376:model-package/{model_name}\",\n",
        "    \"eu-north-1\": f\"arn:aws:sagemaker:eu-north-1:136758871317:model-package/{model_name}\",\n",
        "    \"ap-southeast-1\": f\"arn:aws:sagemaker:ap-southeast-1:192199979996:model-package/{model_name}\",\n",
        "    \"ap-southeast-2\": f\"arn:aws:sagemaker:ap-southeast-2:666831318237:model-package/{model_name}\",\n",
        "    \"ap-northeast-2\": f\"arn:aws:sagemaker:ap-northeast-2:745090734665:model-package/{model_name}\",\n",
        "    \"ap-northeast-1\": f\"arn:aws:sagemaker:ap-northeast-1:977537786026:model-package/{model_name}\",\n",
        "    \"ap-south-1\": f\"arn:aws:sagemaker:ap-south-1:077584701553:model-package/{model_name}\",\n",
        "    \"sa-east-1\": f\"arn:aws:sagemaker:sa-east-1:270155090741:model-package/{model_name}\",\n",
        "}\n",
        "\n",
        "# Specify the model you want to use\n",
        "if region not in model_package_map.keys():\n",
        "    raise Exception(f\"Current boto3 session region {region} is not supported.\")\n",
        "\n",
        "model_package_arn = model_package_map[region]"
      ],
      "metadata": {
        "id": "rJYyYcfsRLi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from jina_sagemaker import Client\n",
        "\n",
        "client = Client(region_name=region)\n",
        "\n",
        "# Choose the name of the endpoint that you created after subscribing to the model\n",
        "endpoint_name = \"jina-embeddings-v2-base-en\"\n",
        "\n",
        "client.create_endpoint(\n",
        "    arn=model_package_arn,\n",
        "    role=role,\n",
        "    endpoint_name=endpoint_name,\n",
        "    instance_type=\"ml.g4dn.xlarge\",\n",
        "    n_instances=1,\n",
        ")"
      ],
      "metadata": {
        "id": "Maxsey4rTSib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef178306-2da1-4416-9a0b-af7ef47a52bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Index Dataset"
      ],
      "metadata": {
        "id": "-By86zDzN7Cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.connect_to_endpoint(endpoint_name=endpoint_name)"
      ],
      "metadata": {
        "id": "HUrApshlunsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this RAG tutorial, we will use a [dataset](https://www.kaggle.com/datasets/maartengr/kurzgesagt-transcriptions?resource=download) (CC0 licenced) containing transcripts of videos from a popular YouTube channel, called [_Kurzgesagt_](https://www.youtube.com/channel/UCsXVk37bltHxD1rDPwtNM8Q) (\"_In a Nutshell_\" in English).\n",
        "\n",
        "The dataset contains, in each row, the title of a video, its url, and then transcript of the video."
      ],
      "metadata": {
        "id": "cZV6VG2eAIl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "073agqr3AMTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('https://drive.google.com/uc?export=download&id=18FO21nrfkQ1Vuee2g_773ON2256nOrlS')"
      ],
      "metadata": {
        "id": "-i63K8oAi8Qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "bbq308Vg7UCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunk and embed data"
      ],
      "metadata": {
        "id": "A69VJ6AVAPP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "def chunk_text(text, max_words=128):\n",
        "    \"\"\"\n",
        "    Divide text into chunks where each chunk contains the maximum number of full sentences under `max_words`.\n",
        "    \"\"\"\n",
        "    sentences = text.split('.')\n",
        "    chunk = []\n",
        "    word_count = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip(\".\")\n",
        "        if not sentence:\n",
        "          continue\n",
        "\n",
        "        words_in_sentence = len(sentence.split())\n",
        "        if word_count + words_in_sentence <= max_words:\n",
        "            chunk.append(sentence)\n",
        "            word_count += words_in_sentence\n",
        "        else:\n",
        "            # Yield the current chunk and start a new one\n",
        "            if chunk:\n",
        "              yield '. '.join(chunk).strip() + '.'\n",
        "            chunk = [sentence]\n",
        "            word_count = words_in_sentence\n",
        "\n",
        "    # Yield the last chunk if it's not empty\n",
        "    if chunk:\n",
        "        yield ' '.join(chunk).strip() + '.'\n",
        "\n",
        "def generate_embeddings(text_df):\n",
        "    chunks = list(chunk_text(text_df['Text']))\n",
        "    embeddings = []\n",
        "\n",
        "    for i, chunk in enumerate(chunks):\n",
        "      response = client.embed(texts=[chunk])\n",
        "      chunk_embedding = response[0]['embedding']\n",
        "      embeddings.append(np.array(chunk_embedding))\n",
        "\n",
        "    text_df['chunks'] = chunks\n",
        "    text_df['embeddings'] = embeddings\n",
        "    return text_df\n",
        "\n",
        "print(\"Embedding text chunks ...\")\n",
        "df = df.progress_apply(generate_embeddings, axis=1)\n"
      ],
      "metadata": {
        "id": "4e1MuouGjeKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2466127-3d5b-42ae-fb89-27fcceca0de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding text chunks ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 171/171 [01:28<00:00,  1.93it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up Semantic Search using Faiss"
      ],
      "metadata": {
        "id": "9aDhBP_17vAU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now use [Faiss](https://github.com/facebookresearch/faiss), an in-memory vector similarity search engine, to find the most similar chunks to a given query.\n",
        "\n",
        "We first need to create an index and add the embeddings to it."
      ],
      "metadata": {
        "id": "82dUlOzNCfwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing vectors in memory\n"
      ],
      "metadata": {
        "id": "Oqdvmig58Oi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "dim = 768  # dimension of the embeddings\n",
        "index_with_ids = faiss.IndexIDMap(faiss.IndexFlatIP(dim))\n",
        "k = 0\n",
        "\n",
        "doc_ref = dict()\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    embeddings = row['embeddings']\n",
        "    for i, embedding in enumerate(embeddings):\n",
        "        normalized_embedding = np.ascontiguousarray(np.array(embedding, dtype='float32').reshape(1, -1))\n",
        "        faiss.normalize_L2(normalized_embedding)\n",
        "        index_with_ids.add_with_ids(normalized_embedding, k)\n",
        "        doc_ref[k] = (row['chunks'][i], idx)\n",
        "        k += 1"
      ],
      "metadata": {
        "id": "b8IWwf92k8KA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector search function"
      ],
      "metadata": {
        "id": "wE7qbTpv8SX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_most_similar_transcript_segment(query, n=3):\n",
        "    query_embedding = client.embed(texts=[query])[0]['embedding']  # Assuming the query is short enough to not need chunking\n",
        "    query_embedding = np.ascontiguousarray(np.array(query_embedding, dtype='float32').reshape(1, -1))\n",
        "    faiss.normalize_L2(query_embedding)\n",
        "\n",
        "    D, I = index_with_ids.search(query_embedding, n)  # Get the top n matches\n",
        "\n",
        "    results = []\n",
        "    for i in range(n):\n",
        "        distance = D[0][i]\n",
        "        index_id = I[0][i]\n",
        "        transcript_segment, doc_idx = doc_ref[index_id]\n",
        "        results.append((transcript_segment, doc_idx, distance))\n",
        "\n",
        "    # Sort the results by distance\n",
        "    results.sort(key=lambda x: x[2])\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "k_SLKBb8-p-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up Question-answering using LLM on Jumpstart"
      ],
      "metadata": {
        "id": "ym1zl1HJDjd9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that this step may take some time approx. 5-10 minutes while deploying an endpoint on AWS Sagemaker."
      ],
      "metadata": {
        "id": "9zxcfZWFszfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.jumpstart.model import JumpStartModel\n",
        "\n",
        "jumpstart_model = JumpStartModel(model_id=\"huggingface-llm-mistral-7b-instruct\", role=role)\n",
        "model_predictor = jumpstart_model.deploy()"
      ],
      "metadata": {
        "id": "MiTRSHj8eY4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3355bf7d-79d6-4b51-d497-c3700a5eb2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using model 'huggingface-llm-mistral-7b-instruct' with wildcard version identifier '*'. You can pin to version '3.0.0' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n",
            "WARNING:sagemaker.jumpstart:Using model 'huggingface-llm-mistral-7b-instruct' with wildcard version identifier '*'. You can pin to version '3.0.0' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Putting it all together for RAG\n",
        "\n"
      ],
      "metadata": {
        "id": "vxQRx35BAfL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query the vector search engine with your question"
      ],
      "metadata": {
        "id": "8Sn_oWaFDrAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = input(\"Enter your question: \")\n",
        "search_results = find_most_similar_transcript_segment(question)"
      ],
      "metadata": {
        "id": "5tlvqezIEVHY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b8f4faf-ec9d-4aff-f5ea-d16cbeb12c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your question: Is global warming real?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(search_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NS-dQ2H27OT9",
        "outputId": "96f40cc5-1bab-4fb7-b627-7839e088617d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(\"Climate change is just too much.  There's never any good news.  Only graphs to get more and more red and angry.  Almost every year breaks some horrible record from the harshest heatways to the most rapid glassy amount.  It's endless and relentless.  We've known for decades that rapid climate change has been caused by the release of greenhouse gases.  But instead of reducing them in 2019 the world was emitting 50% more CO2 than in the year 2000.  And emissions are still rising.  Why is that? Why is it so hard to just stop emitting these gases? Our collective CO2 emissions can be expressed as a product of four factors and their relationship with each other.\", 44, 0.7914946), (\"A decade ago, for lack of action and perspective, many scientists assumed a four-plus degree world was our future, and a lot of public communication focused on exactly this future path.  Luckily, it's much less likely that this version of the apocalypse will come to pass.  If current climate policies stagnate, we're likely to end up with warming of around 3 degrees Celsius by 2100.  Which is scary and tragic and far from acceptable.  But this is actually good news.  How? In the last decade, we've seen enough progress that most scientists now think that we have likely avoided a apocalypse to climate change.  Although substantial risk still remains, we can pretty confidently say that humanity isn't going anywhere.  Civilisation might have to change, but it will endure.\", 15, 0.7959831), (\"Some of the most widely shared stories about climate change are that it is an existential threat, the end of human civilization, and maybe even our own extinction event, and that it's basically unavoidable now.  But what does science actually say? As of 2022, the global average temperature has risen 1. 2 degrees Celsius compared to pre-industrial times.  Limiting warming to 1. 5 degrees was the most ambitious goal of the Paris Agreement, but we are not likely to meet it.  Already with the warming we have today, hot places will get hotter, web places wetter, and the risk and strength of extreme weather events increase significantly.  Warming beyond two degrees makes all of these extremes more extreme.\", 15, 0.82705426)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Templating a prompt for LLM"
      ],
      "metadata": {
        "id": "vuXpASfKDl7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from string import Template\n",
        "\n",
        "prompt_template = Template(\"\"\"\n",
        "  <s>[INST] Answer the question below only using the given context.\n",
        "  The question from the user is based on transcripts of videos from a YouTube\n",
        "    channel.\n",
        "  The context is presented as a ranked list of information in the form of\n",
        "    (video-title, transcript-segment), that is relevant for answering the\n",
        "    user's question.\n",
        "  The answer should only use the presented context. If the question cannot be\n",
        "    answered based on the context, say so.\n",
        "\n",
        "  Context:\n",
        "  1. Video-title: $title_1, transcript-segment: $segment_1\n",
        "  2. Video-title: $title_2, transcript-segment: $segment_2\n",
        "  3. Video-title: $title_3, transcript-segment: $segment_3\n",
        "\n",
        "  Question: $question\n",
        "\n",
        "  Answer: [/INST]\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "prompt_for_llm = prompt_template.substitute(\n",
        "    question = question,\n",
        "    title_1 = df.iloc[search_results[0][1]][\"Title\"].strip(),\n",
        "    segment_1 = search_results[0][0],\n",
        "    title_2 = df.iloc[search_results[1][1]][\"Title\"].strip(),\n",
        "    segment_2 = search_results[1][0],\n",
        "    title_3 = df.iloc[search_results[2][1]][\"Title\"].strip(),\n",
        "    segment_3 = search_results[2][0]\n",
        ")"
      ],
      "metadata": {
        "id": "x5p1_KPFEtC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt_for_llm)"
      ],
      "metadata": {
        "id": "WDL_XomJ0Cra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc60a512-7375-475c-f202-3b59efe085f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  <s>[INST] Answer the question below only using the given context.\n",
            "  The question from the user is based on transcripts of videos from a YouTube\n",
            "    channel.\n",
            "  The context is presented as a ranked list of information in the form of\n",
            "    (video-title, transcript-segment), that is relevant for answering the\n",
            "    user's question.\n",
            "  The answer should only use the presented context. If the question cannot be\n",
            "    answered based on the context, say so.\n",
            "\n",
            "  Context:\n",
            "  1. Video-title: Is It Too Late To Stop Climate Change? Well, it's Complicated., transcript-segment: Climate change is just too much.  There's never any good news.  Only graphs to get more and more red and angry.  Almost every year breaks some horrible record from the harshest heatways to the most rapid glassy amount.  It's endless and relentless.  We've known for decades that rapid climate change has been caused by the release of greenhouse gases.  But instead of reducing them in 2019 the world was emitting 50% more CO2 than in the year 2000.  And emissions are still rising.  Why is that? Why is it so hard to just stop emitting these gases? Our collective CO2 emissions can be expressed as a product of four factors and their relationship with each other.\n",
            "  2. Video-title: We WILL Fix Climate Change!, transcript-segment: A decade ago, for lack of action and perspective, many scientists assumed a four-plus degree world was our future, and a lot of public communication focused on exactly this future path.  Luckily, it's much less likely that this version of the apocalypse will come to pass.  If current climate policies stagnate, we're likely to end up with warming of around 3 degrees Celsius by 2100.  Which is scary and tragic and far from acceptable.  But this is actually good news.  How? In the last decade, we've seen enough progress that most scientists now think that we have likely avoided a apocalypse to climate change.  Although substantial risk still remains, we can pretty confidently say that humanity isn't going anywhere.  Civilisation might have to change, but it will endure.\n",
            "  3. Video-title: We WILL Fix Climate Change!, transcript-segment: Some of the most widely shared stories about climate change are that it is an existential threat, the end of human civilization, and maybe even our own extinction event, and that it's basically unavoidable now.  But what does science actually say? As of 2022, the global average temperature has risen 1. 2 degrees Celsius compared to pre-industrial times.  Limiting warming to 1. 5 degrees was the most ambitious goal of the Paris Agreement, but we are not likely to meet it.  Already with the warming we have today, hot places will get hotter, web places wetter, and the risk and strength of extreme weather events increase significantly.  Warming beyond two degrees makes all of these extremes more extreme.\n",
            "\n",
            "  Question: Is global warming real?\n",
            "\n",
            "  Answer: [/INST]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Send prompt to LLM and print result"
      ],
      "metadata": {
        "id": "tw1VK0dGD0TR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "payload = {\"inputs\": prompt_for_llm}\n",
        "model_predictor.predict(payload)"
      ],
      "metadata": {
        "id": "ldpEjxfJ-BmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89a5bf7c-df07-4ea8-859c-a6b042e8ca8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"Based on the context provided, the answer is: Yes, global warming is real and it is causing significant changes to the Earth's climate, such as rising temperatures and more frequent extreme weather events. According to the transcripts, the global average temperature has already risen by 1.2 degrees Celsius compared to pre-industrial times. Global warming is primarily caused by the release of greenhouse gases, particularly carbon dioxide, into the atmosphere. Despite the\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean up all Sagemaker Endpoints"
      ],
      "metadata": {
        "id": "JgEYvaErWyKE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's super important to do this *EVERY TIME* you deploy an endpoint!!!"
      ],
      "metadata": {
        "id": "S01M0hh7wiIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.delete_endpoint()\n",
        "client.close()"
      ],
      "metadata": {
        "id": "xXKvMt5eW1al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_predictor.delete_model()\n",
        "model_predictor.delete_endpoint()"
      ],
      "metadata": {
        "id": "BlWTzaefgiba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W1oWUsOtwmtH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}