{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "organized-oxygen",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Jina Workshop @ EuroPython: Building a Neural Image Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-makeup",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "In this workshop we will build a neural search engine for images of Pokemons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-compression",
   "metadata": {},
   "source": [
    "# Downloading data and model\n",
    "\n",
    "Skip this if you've already downloaded them.\n",
    "\n",
    "## Download and Extract Data\n",
    "\n",
    "For this example we're using Pokemon sprites from [veekun.com](https://veekun.com/dex/downloads). To download them run:\n",
    "\n",
    "```sh\n",
    "sh ./get_data.sh\n",
    "```\n",
    "\n",
    "## Download and Extract Pretrained Model\n",
    "\n",
    "In this example we use [BiT (Big Transfer) model](https://github.com/google-research/big_transfer), To download it:\n",
    "\n",
    "```sh\n",
    "sh ./download.sh\n",
    "```"
   ]
  },
  {
   "attachments": {
    "07a57670-02d0-4b37-89d4-e40fa91fe617.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoAgMAAADxkFD+AAAADFBMVEX///+l1oQZEBBKpVrbdx+K\nAAABKUlEQVQY05XQMUsCYQDG8f+9cXBYOGYY2BUNfYYmv8TpEHjSEk6uhcFdRmCbi+HoUsRrdAUa\nbecYTS7tRyCEoS4N5sG9DXfW3DP9pmf4w78n/mgMfmk+LLV/Xk6UvhQJVzq7uYRGOn+Q0GzqteOY\nT/nidza+D1/9yaYLpOphUJ3kAmD7UJ7VJusBYFasVtjLtAET62j6tdUGDCrOYmi3AVO7nkV9pwHU\n9aI386IXoNEqbX6G4QZw0ypdqejuFMSOVairWT8AYVnWWHm+C8ZUdl3fk4DISklVfQB72luB0mIO\nGEip2SoChFbmwhkpF+jPtZPw0XaB9L1V8JrFDoAxsqNBJgAwcn6Uj7mmj+UwptCd954dADBSz55y\n43rdecqPyWogomV+l1v4AZcxc6uK8D1EAAAAAElFTkSuQmCC\n"
    },
    "4fdcaf41-1adb-4eef-9770-94a112369dfe.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAADAAAAAwAgMAAAAqbBEUAAAADFBMVEX///+l1oQZEBBKpVrbdx+K\nAAABc0lEQVQokWNgoA54dQDBZrr6AsGxDn2E4Chdb2iAcxr2NxjA2MwMegwKcP0MXAwcMA4PkMsO\n43AwMDaIwTgmDIwFcI4CA2tCHIyjwhCaCOfohtbX1sM43KGvfv6Acbi2r9q9A2qlUtOiVfsWQG3p\nUF60atcGqMGSXS9WvTq1Asxp23tyl/aaRUpgzgq9q/9WbQotA/uogWNt3aqV88PBnmBq6P7Htnr3\nV7AnOBKYXrCv3r3XCWxaxKoV8qtW708DcRSrGWPjVijtvgHiqE5hCL+1gEF7O4jDF8q49fcbBqZt\nIA7n1NDQf3EHgCEE0lN6NfT/9EdruEEczbCQ9v/zf/8CO+dFeND7/6v/hoOd0xUapf23bovoA1DY\ndjQo6T+MfxIO4nCJhrrGN8Q/jQdx9FhDQ6sb4nf9B3FWNa1avk60/v06oAFM1av2n/o1ff3rFQlA\njuKr//9X6Um3rQQp6+tbtYrvVdW8JlhEMm9e85qBaAAAlDCFn/mqVXMAAAAASUVORK5CYII=\n"
    },
    "dd9fe45f-6be4-4822-ae92-2d281b56c0ff.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAADgAAAA4AgMAAADV6NONAAAADFBMVEX///+l1oQZEBBKpVrbdx+K\nAAACpklEQVQYGQXBQWhbdRzA8e/7h7I0kfYU9LTGYaBLYT15TtzRUxz9J7GFpHhwI8PhTaho/tbD\n3PAQoXGjXrJCIPk9zdulMFN8Cd6FXdYNPTQOh90rJvMQDS/b++/zAQBiLqBaAMBSt3qfwA0NCSDW\nQs+WdN2OSBq4uEEqegcthmRAbK9A6kuDsw3KdhIdSNUNThkYRL7sOcXP7fBFBVizQ+d5sdwfDF9U\nAGWhePfuj+tQNcBgyPTa/d+2ceoG+O5l7NW3n/1rSNWAWIFYFHv57mEgBlAFnP9uvlEXrgGwx7T8\n93KQzykDKM20mDn+hRzbwKL+Qte6f/wPvAUsXp3W7kTuCXAeUIPjrp5HD5ed904MMAga1XrUyA0L\nVw0oe4v6SbiXG26cjUCFaXKPg/YyqfkMkqMGy+eCdp43oxkkd/OwIO0CO74PSuUhddT9MD9avQQs\nFqB44/lmaUQcWPwU51j+LA4MAOvPOPf7ykHRMwCsd/XWk+rTYs8AcEma3qmMvhcAkLl4t1da/f0O\nQMIZhN431dbR/scGSHdLkX9Bnro/NGtAJ1Wf+KvnD37SlaZBqTvR/EF6pV96pHdaqHtbnrRWa97E\nf6W3iScqSZFea+CH48cdEs0d1dab5ro/Hz8rE9dHxtl89MGN+cT/J+DtrZ/NgtZa3F5/XOTilo/W\nWldE+uMnZPY7zidaH1YDkfGIhIjWGxldD0VkBGsfNXXhlr4eiTww4F7I6Ctf6WCW7Z2CYjejy7dL\nYXB5EEH2ysOmLietneizCL7u6R3PTqy1YRTBTdvLypq1Ezu3h4Y190Ck40YDO63+lUZJKHYmrvUa\npXkasiPPRpEXSaMUGkjsuta69ky1S6cA6n0RGxDPVn8FoLWgA4in13cBWBIB1L3aKgAAQMLAa79M\nR9jveT6JAAAAAElFTkSuQmCC\n"
    }
   },
   "cell_type": "markdown",
   "id": "steady-singapore",
   "metadata": {},
   "source": [
    "# The problem\n",
    "\n",
    "We want to search Pokemon by pictures! For example \n",
    "\n",
    "![1.png](attachment:07a57670-02d0-4b37-89d4-e40fa91fe617.png)\n",
    "\n",
    "May return\n",
    "\n",
    "![2.png](attachment:4fdcaf41-1adb-4eef-9770-94a112369dfe.png) ![3.png](attachment:dd9fe45f-6be4-4822-ae92-2d281b56c0ff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-badge",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-heading",
   "metadata": {},
   "source": [
    "Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "experimental-bacteria",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-06 15:58:41.569240: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-07-06 15:58:41.569262: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from jina.types.document.generators import from_files\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from shutil import rmtree\n",
    "\n",
    "from jina import Flow, DocumentArray, Document\n",
    "\n",
    "from jinahub.image.normalizer import ImageNormalizer\n",
    "from jinahub.image.encoder.big_transfer import BigTransferEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-policy",
   "metadata": {},
   "source": [
    "Some configuration options.\n",
    "\n",
    "- restrict the nr of docs we index\n",
    "- the path to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "exposed-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = int(os.environ.get('JINA_MAX_DOCS', 1))\n",
    "image_src = 'data/**/*.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-outside",
   "metadata": {},
   "source": [
    "Environment variables\n",
    "\n",
    "- workspace (folder where the encoded data will be stored)\n",
    "- port we will listen on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "later-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = './workspace'\n",
    "os.environ['JINA_WORKSPACE'] = workspace\n",
    "os.environ['JINA_PORT'] = os.environ.get('JINA_PORT', str(45678))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-ceramic",
   "metadata": {},
   "source": [
    "We need to make sure to not index on top of an existing workspace. \n",
    "\n",
    "This can cause problems if you are using different configuration options between the two runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "commercial-sight",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(workspace):\n",
    "    print(f'Workspace at {workspace} exists. Will delete')\n",
    "    rmtree(workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-conspiracy",
   "metadata": {},
   "source": [
    "# Flows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-sullivan",
   "metadata": {},
   "source": [
    "The Flow is the main pipeline in Jina. It describes the way data should be loaded, processed, stored etc. within the system. \n",
    "\n",
    "It is made up of components (called Executors), which are the ones doing the specific task.\n",
    "\n",
    "Ex. we have an Encoder Executor, which loads the model and *encodes* that data; crafter Executor, which preprocesses the data; Indexer Executor, which stores and retrieves the data etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-thomson",
   "metadata": {},
   "source": [
    "## Index Flow\n",
    "\n",
    "Depending on your need the Flow can be configured in different ways. \n",
    "\n",
    "While indexing (storing) data, we can optimize the pipeline to process the data in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "central-stupid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m\u001b[0m"
     ]
    }
   ],
   "source": [
    "f = Flow.load_config('flows/index.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "correct-giant",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/svg/JSV7aW5pdDogeyd0aGVtZSc6ICdiYXNlJywgJ3RoZW1lVmFyaWFibGVzJzogeyAncHJpbWFyeUNvbG9yJzogJyMzMkM4Q0QnLCAnZWRnZUxhYmVsQmFja2dyb3VuZCc6JyNmZmYnLCAnY2x1c3RlckJrZyc6ICcjRkZDQzY2J319fSUlCmdyYXBoIExSCmdhdGV3YXkoZ2F0ZXdheSk6OjpHQVRFV0FZIC0tPiB8Uk9VVEVSLVJPVVRFUnxsb2dnZXIobG9nZ2VyKTo6OlBPRApsb2dnZXIobG9nZ2VyKTo6OlBPRCAtLT4gfFJPVVRFUi1ST1VURVJ8Y3JhZnRlcihjcmFmdGVyKTo6OlBPRApjcmFmdGVyKGNyYWZ0ZXIpOjo6UE9EIC0tPiB8Uk9VVEVSLVJPVVRFUnxsb2dnZXIyKGxvZ2dlcjIpOjo6UE9ECmxvZ2dlcjIobG9nZ2VyMik6OjpQT0QgLS0+IHxST1VURVItUk9VVEVSfGVuY29kZXIoZW5jb2Rlcik6OjpQT0QKZW5jb2RlcihlbmNvZGVyKTo6OlBPRCAtLT4gfFJPVVRFUi1ST1VURVJ8Z2F0ZXdheV9FTkQoZ2F0ZXdheSk6OjpHQVRFV0FZCmNsYXNzRGVmIFBPRCBmaWxsOiMzMkM4Q0Qsc3Ryb2tlOiMwMDk5OTkKY2xhc3NEZWYgSU5TUEVDVCBmaWxsOiNmZjY2NjYsY29sb3I6I2ZmZgpjbGFzc0RlZiBKT0lOX0lOU1BFQ1QgZmlsbDojZmY2NjY2LGNvbG9yOiNmZmYKY2xhc3NEZWYgR0FURVdBWSBmaWxsOiM2RTcyNzgsY29sb3I6I2ZmZgpjbGFzc0RlZiBJTlNQRUNUX0FVWF9QQVNTIGZpbGw6I2ZmZixjb2xvcjojMDAwLHN0cm9rZS1kYXNoYXJyYXk6IDUgNQpjbGFzc0RlZiBwZWEgZmlsbDojMDA5OTk5LHN0cm9rZTojMUU2RTcz\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f.plot('index.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-details",
   "metadata": {},
   "source": [
    "The Flow is a context manager (like a file handler).\n",
    "\n",
    "We load data into the pipeline from the directory we provided above. \n",
    "\n",
    "`request_size` dictates how many images should be sent in one request (~batching)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c88e07c3-ff42-4211-9670-17ae230ef060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = DocumentArray(from_files(image_src, size=num_docs, read_mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dea166a-e418-4e3a-8d7b-3b9dcc7b95e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00P\\x00\\x00\\x00P\\x08\\x06\\x00\\x00\\x00\\x8e\\x11\\xf2\\xad\\x00\\x00\\x03\\x13IDATx\\xda\\xed\\xdb\\xbdq\\xdb@\\x10\\x05`\\x95\\xc0v\\x1c\\xa2\\r\\xb5\\xc1\\xd0%8U\\xa8\\x12\\x18\\xba\\x05\\x85n\\xc1%(T\\n{e\\xbf\\x99\\xa7\\xa7\\xbd#(\\x92\\xb8\\xc3\\xe1ifG\\xc4\\x1f9\\xf8\\xb4{\\x7f\\xa0\\x1e\\xe6y~p|=\\x8c`@\\x03\\x1a\\xd0\\x80\\x0e\\x03\\x1a\\xd0\\x80\\x06t\\x18\\xd0\\x80\\x064\\xa0\\xc3\\x80\\x064\\xa0\\x01\\x1d\\x064\\xa0\\x01o\\x11\\xc7\\xc7i\\xe60\\xe0\\x05p\\xa7\\x1f\\xd3\\xfc\\xf6r\\xfc\\x10\\xbdA\\xf6\\x9bi\\xbf\\x9f?\\x85B\\x1a\\x90\\xe0\\x90m%\\xbc^\\x11\\xbb(S\\xe0\\xc4k\\xde\\xd6\\x88c\\x9c\\xa5\\x81x8\\x1c\\xe6]\\x02*^D\\x96}@e4m\\x0f[\"6\\x05\\x0c\\x04@\\xbdN\\xd3\\xfc\\xf8m\\xfa\\x84\\xa7\\x9dH)Z!6\\x07\\x8cx\\xcf\\xc4\\xbf?@\\\\\\x8a\\xd6\\x03b3@\\x94f\\xdcx\\xc0!\\x140k\\xf7v\\x0f\\x08\\x08\\x05<\\t`\\x1c\\xff\\xf9\\xeb\\xedC\\xa0\\xcd\\xeb\\x05\\xb1\\t\\xa0\\x02\\xbcgc\\x05\\x10\\xd9\\xca\\x90%\\xc4\\xe1\\x01\\xf9\\xc6\\xb9\\x93\\x88\\xd7Y\\xfb\\xc7\\xe7D\\xf6\\x9dC\\\\{l\\xd8\\x0c\\x90\\xb3\\xabT\\x8e8\\xc6\\xed\\xa0\\x02f\\xd7\\xaf\\x99\\x85\\xcd\\x00\\x03\\xe3\\xe9\\xf9\\xa5\\n\\x98\\xcdR\\x180\\xae\\xcf\\xb2p7\\x80\\x9ca\\xb5\\x0c,u(\\x00\\xd4\\xeb\\x87\\x07\\x04\\x9efX)\\x0bq\\\\\\xf1\\xa6\\xe9\\xdf1mWw\\x05X\\xcb@\\r\\xc6S@\\xf4\\xd4\\xc3\\x03\\x96\\x10\\x97\\xe0\\x01\\x8e\\xf1\\xf0\\x1e-\\xf0\\xba\\x00\\xcc\\x10u\\xd6\\xc1p\\x8aW\\x03\\x8c\\xf3\"\\x86\\x9c\\xca)\\xa2n#\\x18.\\xce\\xd1r\\xcdJ\\x17p\\xc0\\x1ev=0C\\x03\\x12\\x869@\\xa8\\xc1\\xe1:\\x86\\x8b\\xf8~|\\x1a\\x1b\\xb0\\x84\\x88\\xe0,*\\xc1\\x01\\x8d\\xe1\\xd6\\xc2\\xeb\\xea\\x99HV\\x9e\\x8c\\xa2\\x9dF\\x86\\x96\\xb5\\x95\\xbb{*\\x07\\x98\\xc8 \\x1d8c\\x7f\\r\\r\\x7f\\x885\\xf0\\xba\\x00\\xe4\\x12\\xcc\\xd0\\xb2}\\xc0\\x04\\x16\\xc7\\xd0\\xeb\\x81\\x8cU\\x02\\xd3\\xc5\\x82\\xc8\\xaas\\xe7\\xec\\xe2\\xa1R\\x80\\xd5 \\x14\\x85\\x87$K\\xce\\xdf\\x05 7\\xfc\\x9a}\\xdc~i\\xe7R\\xcbB\\xeeq\\xd7j\\xf7\\x9a\\xb6\\x81Z\\xba\\xe7\\xda/\\x00\\x021\\xae\\xc5\\xf5\\xda\\xe3\\xb6\\xc8\\xc6\\xa6C\\x96%7\\x0b@d\\x19:\\x10\\x1d\\xf3q/\\xbcY@.\\xd3\\xec\\xd85\\xe0\\\\\\xc6\\xa5\\xf1\\xdf\\xe6{a.7\\x9e\\t\\\\;/e0\\xfe\\x0c|N\\xab!\\xcc]\\x01\\xb9m\\xbaff\\xc0\\xf8\\xd9\\xfbor\\x18S*U\\xdc`m\\x8au)\\xa2\\xbe\\x17f\\x19k\\xcdu\\xef\\x02\\x187\\xc13\\x05\\xbe\\x114\\xf4h\\xd8\\xf1\\xbc\\xf7+\\x805<\\x94\\xee\\xe6\\x01\\x15\\x92\\xb7q\\xe3\\x8c\\x18\\xfbG\\xc1\\xbb)`i\\xbezi\\x19g\\xab,\\x0c\\xd7\\x13\\xdeU\\x9d\\x88\"\\x9e\\xfe\\x7f\\xbfe\\t`\\x86\\x088}\\xea\\xc6x\\xe8H\\x86\\xf9\\x929\\xca\\n7\\x8d/\\x08\\xf1\\x8c![\\x82\\xe2\\xa9\\x97\\xc2\\x01^\\xcb\\xb57\\xb8\\x9b\\x00\\x96VS\\xb0\\x1f\\xbf\\xb9\\xd7\\xcc\\xc0\\xb2i]\\xcb%\\xaaU\\x00/Y])\\xa1m\\t\\xean%\\xcc\\x0fs\\xb0}n\\x99j\\xcb`w_L\\x00 \\x97\\xf1H`\\xab\\xac\\xc6p&\\x8e\\n\\xb7\\xcar\\xd6\\xe8x\\xfeoM\\x03\\x1a\\xd0\\x80\\x064\\x82\\x01\\rh@\\x03:\\x0ch@\\x03\\x1a\\xd0a@\\x03n,\\xfe\\x00\\xd5-B-\\xfbj]\\x17\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f429afbf-4826-46d1-9c23-b284c2f660ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jina import Executor, requests\n",
    "from jina.logging.logger import JinaLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4f18983-c560-4c77-89df-1d14eac640c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogger(Executor):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.logger = JinaLogger('MyLogger')\n",
    "    \n",
    "    @requests\n",
    "    def log(self, docs, **kwargs):\n",
    "        self.logger.warning(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "78543b45-9364-4ece-a53c-d80cb52859ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00P\\x00\\x00\\x00P\\x08\\x06\\x00\\x00\\x00\\x8e\\x11\\xf2\\xad\\x00\\x00\\x03\\x8bIDATx\\xda\\xed\\xdc\\xcdq\\xdb0\\x10\\x05`\\x95\\xe0\\x12tu\\x19\\xbe\\xe6\\xa82|u\\tj\\xc1e\\xf8\\xa8k\\x8e.\\x81-\\xa4\\x84\\\\\\x19/G\\xeb<\\xaewA\\xf0\\x1f\\x84\\x1egv\\xecP\\x16\\'\\xf8\\xb4\\x00\\x16 \\xedS\\xdb\\xb6\\'\\xc6\\xf4 \\x02\\x01\\tH@\\x022\\x08H@\\x02\\x12\\x90A@\\x02\\x12\\x90\\x80\\x0c\\x02\\x12\\x90\\x80\\x04,6\\xce\\x97k\\x1b\\x05\\x01\\x9dx}zj%\\x14\\xe9\\xf5\\xf6\\xa7\\xbd6\\x7f{!\\xe7$\\xf6\\x80,\\x1e\\xee\\xf6|\\xee\\xbe\\xa6\\xe0ll\\tY,\\x9e\\x1cS\\xf0,\\xe4\\xc3\\x01*^\\xfb\\xf9;\\xc4\\xf3\\x00{\\xe7\\xef\\xd9\\xab\\xf10\\x80]c\\xbf\\xe0$\\xba\\xec38\\xb9x\\xf2^\\x8c5\\x11\\x8b\\xc2\\xb3\\x8d\\x0e\\x91\\x1c@\\xc4\\xc3\\x0fam\\xc4\\xb2\\xb2\\xef\\xf2\\xeb\\x7f\\x833\\xc6\\xb8\\x1e,\\xe2\\xe9\\xb1\\x01bQx\\n\\x98\\x8b\\xe7f\\x9f9\\x08\\x98\\x03\\x08\\xdd\\xbfw\\x98\\x0c\\\\\\x03\\xb1\\x08\\xc0\\xae\\xe1w\\xc01x.\\xa0va\\x07\\xafJ@]]x\\x13\\x87\\xc4\\xcb\\xfbG\\x17\\xb9\\x80\\xa9\\xe8>\\xa0Z\\x01\\xbd\\x10\\xb8\\xac\\x02\\x1a\\xc7\\xbf \\xf3\\xaa\\x06\\xd4\\x0c\\xc3LS\\xbc^a\\x8c\\x93\\x86\\xf9\\xf9\\xa8|\\xa9\\x1e\\x10wX,\\xa0\\xe2\\xd9e\\x9d\\x07\\x18uc\\x9c\\x9c\\xaa\\x06t\\xc7\\xb9`U\\x11\\x01b\\x1d\\x89x=\\xc4\\x1a\\xcb\\x98\\xaf#9\\xb6\\xd9.\\x98\\xcaBD\\xb4\\x80\\xd5\\xd6\\x81\\x11`\\x87\\x035\\xa2|o3\\xd5\\xeb\\xc6\\x16n\\xad\\xec+\\xbf\\x0b\\x03\\xa2\\x87\\xa7\\xaf\\xf7fr\\xd8GD\\xf8S\\xd7\\xd4J\\x01\\xa5q\\xb6\\xdeK\\xd5~C\\x88\\x88\\xae\\xd7\\xaej7\\xc6\\xde\\xc7@\\xc0\\x1f\\x195\\x12Q\\xb3\\x19c\\xad\\xec\\xdb\\x05\\xd0\\xe2(\\x9e6<\\xc2\\x1b*\\xb8\\xed\\x07 \\xd7\\xd5\\xa8fC\\xd5N\\x16\\x8ab\\xb3\\'\\x02\\xb4PC\\xb16\\xde.\\x80\\xde,\\x8a\\xd9\\x97\\x9aL\\xc6 n\\x81\\xb7; v\\xd9\\xa6iZ\\x0f\\x18\\xbbh\\x0e\\xa0v\\xdf\\xc3\\xdd\\xd6\\xbc\\\\\\xce\\xad\\xc6\\x10\\xa2\\x1d\\xef\\x04\\xef>\\x9b\\xfc\\x18\\xeb,N)p\\x8b\\x01*Z\\xf3\\xf9\\xfe\\x1d)H\\xcd2\\x1d\\xe0\\x15I\\x0e\\x81\\xf4\\x90t|D|\\xfb\\xda\\xd6]w\\x11@\\x0bg\\xc3C\\xb4\\x80\\x88\\xa8\\xdd\\xd7>\\xb2!\\xb0\\xda\\xc5\\xe5()\\x13\\x17\\xc3\\xbb^_\\xbeAn\\x1fo]\\xc8y\\xaf1\\x88g\\xc7\\xbd(\\x03\\xed\\x11!n\\xfdt\\xc2\"\\x80\\x8a\\x87@rN\\x10\\xa3,\\xb4\\xb5\\xda\\xd0\\nD\\xcek&zc\\xe2^O\\',\\x92}Q\\x96i&\\x0ee\\xa1`\\xa7\\x8a\\xe5T\\xa9\\x12\\xcd\\xdcv\\xa6?\\x1c f\"vo\\x0b\\xa8\\xaf)\\x88\\xd7x\\xaf\\xcb{\\xe3h\\xb4\\xb4+n)\\xe7M\\x1e9\\x88\\x08\\xa9\\xe7\\xe5Z\\xfao\\xcd@\\xfc\\x19\\xef9@|]\\xdfo7\\x13\\xf0\\xbdE\\x03\\xead\\x11uU\\x9bm\\x11\\xa6\\x8d\\xd4\\x83\\x94\\x08\\x93\\xba\\x0e\\xd6\\x9b\\xc5N\":Y\\xa4\\xc6\\xbbh\\xf6\\x8d\\xce\\x8f\\xc9@\\x9b\\xc5\\xb6\\xab\\x17\\xbb\\x99 \\xffiECD;#\\x8fY\\xe6M\\r/\\x0b\\xb7\\xaa\\x07g\\xafm\\x11\\x0echI\\x97S\\xda\\xcc\\x01<\\xccf\\x02\\x8em\\x826\\x15p\\x0e\\xa2\\xed\\xc6\\x87{F\\xda6D\\x1b3\\xe7Z\\xdex\\x17\\x8d\\x8d\\x98\\x85\\x87~J\\x7f\\xc9,\\x982\\x99x\\xf5&\\x7fO$1\\xc1\\xe4\\xd4\\x9b\\x04\\x9c8\\x94\\xcc\\x19\\x8b\\x1f\\xfeW\\xbdp3#\\xda\\xd0 \\xe0\\x88\\x12\\x8b\\x80#o\\x1bx\\xc5~\\xd5O&\\xe4bH\\xb7\\xcc\\xb9m@\\xc0\\x81\\xb5\\xb7w\\xff\\xc5\\x0b\\xdd\\xe4 \\xa0\\xb3\\x03n!\\xbd\\x98\\xbb>\\xafr\\x0c\\xf4\\xb2\\xcfb\\xe2\\xee\\x10\\'\\x91\\xc4\\xb8\\x96\\x13\\xac\\x033\\xea<\\x0c\\\\\\x85\\xc8\\xf7\\\\\\x89\\xcc\\\\\\xe2\\x11\\x90\\x7ft\\x82\\x80\\x0c\\x02\\x12\\x90\\x80\\x04d\\x10\\x90\\x80\\x04$ \\xc3\\xc4?\\x06gF\\xa6\\xeb\\x9e\\xd6c\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47ca4748-fda2-4e49-be5f-a517bc3e33b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0;32m\u001b[0m\u001b[0m         logger@76588[I]:ready and listening\n",
      "\u001b[1;30m\u001b[1;30m\u001b[0m\u001b[0m\u001b[1;30m\u001b[0m\u001b[0;32m\u001b[0m        crafter@76588[I]:ready and listening\n",
      "\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[0;33mBigTransferEncoder@84953[W]:You tried to use a GPU but no GPU was found on your system. Defaulting to CPU!\n",
      "\u001b[0m\u001b[0;32mBigTransferEncoder@84953[I]:BiT model path: pretrained\n",
      "        logger2@76588[I]:ready and listening\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-06 16:42:17.638318: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-07-06 16:42:17.638386: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-07-06 16:42:17.638437: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (x1): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-06 16:42:17.979837: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "\u001b[0;32m        encoder@76588[I]:ready and listening\n",
      "\u001b[0m\u001b[0;32m        gateway@76588[I]:ready and listening\n",
      "\u001b[0m\u001b[1;30m\u001b[0m           Flow@76588[I]:ðŸŽ‰ Flow is ready to use!\n",
      "\tðŸ”— Protocol: \t\t\u001b[1mGRPC\u001b[0m\n",
      "\tðŸ  Local access:\t\u001b[4m\u001b[36m0.0.0.0:33113\u001b[0m\n",
      "\tðŸ”’ Private network:\t\u001b[4m\u001b[36m192.168.178.144:33113\u001b[0m\n",
      "\tðŸŒ Public address:\t\u001b[4m\u001b[36m2001:16b8:4626:9300:b1eb:24b7:e83:ad65:33113\u001b[0m\n",
      "\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[0;33m       MyLogger@84910[W]:2\n",
      "\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[0;31m        logger2@84934[E]:TypeError(\"object of type 'NoneType' has no len()\")\n",
      " add \"--quiet-error\" to suppress the exception details\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cristian/envs/europython/lib/python3.7/site-packages/jina/peapods/runtimes/zmq/zed.py\", line 289, in _msg_callback\n",
      "    self._zmqlet.send_message(self._callback(msg))\n",
      "  File \"/home/cristian/envs/europython/lib/python3.7/site-packages/jina/peapods/runtimes/zmq/zed.py\", line 275, in _callback\n",
      "    self._pre_hook(msg)._handle(msg)._post_hook(msg)\n",
      "  File \"/home/cristian/envs/europython/lib/python3.7/site-packages/jina/peapods/runtimes/zmq/zed.py\", line 227, in _handle\n",
      "    groundtruths_matrix=self.groundtruths_matrix,\n",
      "  File \"/home/cristian/envs/europython/lib/python3.7/site-packages/jina/executors/__init__.py\", line 188, in __call__\n",
      "    self, **kwargs\n",
      "  File \"/home/cristian/envs/europython/lib/python3.7/site-packages/jina/executors/decorators.py\", line 103, in arg_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_76588/780235031.py\", line 9, in log\n",
      "    self.logger.warning(len(docs))\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[0;31m        encoder@84953[E]:AttributeError(\"'NoneType' object has no attribute '__len__'\")\n",
      " add \"--quiet-error\" to suppress the exception details\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cristian/envs/europython/lib/python3.7/site-packages/jina/peapods/runtimes/zmq/zed.py\", line 289, in _msg_callback\n",
      "    self._zmqlet.send_message(self._callback(msg))\n",
      "  File \"/home/cristian/envs/europython/lib/python3.7/site-packages/jina/peapods/runtimes/zmq/zed.py\", line 275, in _callback\n",
      "    self._pre_hook(msg)._handle(msg)._post_hook(msg)\n",
      "  File \"/home/cristian/envs/europython/lib/python3.7/site-packages/jina/peapods/runtimes/zmq/zed.py\", line 227, in _handle\n",
      "    groundtruths_matrix=self.groundtruths_matrix,\n",
      "  File \"/home/cristian/envs/europython/lib/python3.7/site-packages/jina/executors/__init__.py\", line 188, in __call__\n",
      "    self, **kwargs\n",
      "  File \"/home/cristian/envs/europython/lib/python3.7/site-packages/jina/executors/decorators.py\", line 103, in arg_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/cristian/envs/europython/lib/python3.7/site-packages/jinahub/image/encoder/big_transfer.py\", line 130, in encode\n",
      "    docs_batch_generator = self._get_docs_batch_generator(docs, parameters)\n",
      "  File \"/home/cristian/envs/europython/lib/python3.7/site-packages/jinahub/image/encoder/big_transfer.py\", line 144, in _get_docs_batch_generator\n",
      "    batch_size = docs.__len__()\n",
      "AttributeError: 'NoneType' object has no attribute '__len__'\n",
      "\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m\u001b[1;30m\u001b[0m"
     ]
    }
   ],
   "source": [
    "with f:\n",
    "    f.post(\n",
    "        on='/index',\n",
    "        inputs=docs,\n",
    "        request_size=64,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-moderator",
   "metadata": {},
   "source": [
    "# Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-cover",
   "metadata": {},
   "source": [
    "When searching we need to make sure the data is processed in serial manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Flow.load_config('flows/query.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-abortion",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.plot('search.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-marking",
   "metadata": {},
   "source": [
    "This will activate the REST API.\n",
    "\n",
    "You can use [Jinabox.js](https://jina.ai/jinabox.js/) to find the Pokemon which matches most clearly. Just set the endpoint to `http://127.0.0.1:45678/api/search` and drag from the thumbnails on the left or from your file manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551fb5de-5b4b-457a-b51c-62ea0e76dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_image = blabla. .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129bb013-d984-4bb1-ba48-14c63aca050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_image.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-reliance",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with f:\n",
    "    f.post(\n",
    "        on='/search',\n",
    "        inputs=search_image\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd61ee-ec07-4e37-a434-d00f4ef1c15e",
   "metadata": {},
   "source": [
    "Retrieving tags (image path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa2190a0-153f-40ed-b8c8-0f13f7143dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-think",
   "metadata": {},
   "source": [
    "# Questions?\n",
    "\n",
    "---\n",
    "\n",
    "# 5 minutes break\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-expense",
   "metadata": {},
   "source": [
    "# Advanced Topics\n",
    "\n",
    "\n",
    "**NOTE**: After configuring these, you will need to re-index your data and search again. \n",
    "\n",
    "## 1. Changing Encoders\n",
    "\n",
    "We can switch the `Encoder` easily.\n",
    "\n",
    "This is the component that is the actual **model**. This encodes the images into a vector space upon which you can perform cosine similarity (or other linear algebra operations).\n",
    "\n",
    "\n",
    "`pods/encode.yml`:\n",
    "\n",
    "```yaml\n",
    "!ImageKerasEncoder\n",
    "with:\n",
    "  model_name: ResNet50V2 # any model could go here\n",
    "  pool_strategy: avg\n",
    "  channel_axis: -1\n",
    "```\n",
    "\n",
    "## 2. Changing Crafters\n",
    "\n",
    "**NOTE** The `CenterImageCropper` and `PngToDiskDriver` are already added. This section explains why and how we add them.\n",
    "\n",
    "These are the components that transform your data. In this case, we crop and resize the image. You can try out other alterations to the images and see if you get better results.\n",
    "\n",
    "In `pods/craft.yml`:\n",
    "\n",
    "- remove `target_size: 96` from `ImageNormalizer`\n",
    "\n",
    "```yaml\n",
    "- !CenterImageCropper\n",
    "with:\n",
    "  target_size: 96\n",
    "  channel_axis: -1\n",
    "metas:\n",
    "  name: img_cropper\n",
    "```\n",
    "\n",
    "We also need to specify the request paths, both for `IndexRequest` and for `SearchRequest`:\n",
    "\n",
    "```yaml\n",
    "      - !CraftDriver\n",
    "        with:\n",
    "          traversal_paths: ['r']\n",
    "          executor: img_cropper\n",
    "```\n",
    "\n",
    "We can save an intermediary file to examine the cropped image to see if everything looks as expected. Add this to the `IndexRequest`:\n",
    "\n",
    "```yaml\n",
    "      - !PngToDiskDriver\n",
    "        with:\n",
    "          prefix: 'crop'\n",
    "```\n",
    "\n",
    "Now you can find the intermediary forms of the file in `workspace/`, under the folders with the given prefix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-cleanup",
   "metadata": {},
   "source": [
    "## 3. JinaD on AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-pocket",
   "metadata": {},
   "source": [
    "### What is JinaD?\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5b6f51-0570-45ad-b075-e6c567192a93",
   "metadata": {},
   "source": [
    "remote flow\n",
    "\n",
    "remote indexing\n",
    "\n",
    "Attendants could query during the workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-imagination",
   "metadata": {},
   "source": [
    "# Questions?"
   ]
  },
  {
   "attachments": {
    "1a98c688-569b-4b08-aa1d-3dbb7fadd38f.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoAgMAAADxkFD+AAAADFBMVEX///+l1oQZEBBKpVrbdx+K\nAAABDElEQVQY02NgIBkwIZgcB+BMhQ0wllVzApTF18kEZTIvUJGDMjn4HKKhTIUJrNUVEOY2h9Cf\nUhDjf5+anyvdAGRxNf1+oPtW7AFIpdKqBmkoUzO0oXqL+AwQkyE0Me+LPIjJwZBZ/+tCPFiUcen7\nf0vrO4DMJtbw9b9X/zsBZHZMjZP+/+u3BJC5bGrctP//1tQA7VKaWtf0//1WoLlMofH//+9fvR9k\n8atVq1b9X70K5BourRWz//9/AXbY1NDU179+gJjcq1ZNzf//D8TUTWBMif/3HqStsYK1aX5nNpDJ\n9PRXaFP8gmggk6Nj0SrWugWhIFElBqbsfY1i0HBo0mjigIaoRoPGAtIiAQDjzWNRFer//AAAAABJ\nRU5ErkJggg==\n"
    },
    "cb8f8cf6-92f7-4b7f-9a75-43029261979b.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoAgMAAADxkFD+AAAADFBMVEX///+l1oQZEBBKpVrbdx+K\nAAABKUlEQVQY05XQMUsCYQDG8f+9cXBYOGYY2BUNfYYmv8TpEHjSEk6uhcFdRmCbi+HoUsRrdAUa\nbecYTS7tRyCEoS4N5sG9DXfW3DP9pmf4w78n/mgMfmk+LLV/Xk6UvhQJVzq7uYRGOn+Q0GzqteOY\nT/nidza+D1/9yaYLpOphUJ3kAmD7UJ7VJusBYFasVtjLtAET62j6tdUGDCrOYmi3AVO7nkV9pwHU\n9aI386IXoNEqbX6G4QZw0ypdqejuFMSOVairWT8AYVnWWHm+C8ZUdl3fk4DISklVfQB72luB0mIO\nGEip2SoChFbmwhkpF+jPtZPw0XaB9L1V8JrFDoAxsqNBJgAwcn6Uj7mmj+UwptCd954dADBSz55y\n43rdecqPyWogomV+l1v4AZcxc6uK8D1EAAAAAElFTkSuQmCC\n"
    }
   },
   "cell_type": "markdown",
   "id": "supported-martin",
   "metadata": {},
   "source": [
    "## 4. Optimization\n",
    "\n",
    "In every Flow that is build with Jina, there are quite some parameters to set.\n",
    "For example, if you use a pre-trained model for encoding, there is no obvious best choice for a given dataset.\n",
    "Jina allows you to try out a lot of different parameters automatically in order to get the best results.\n",
    "\n",
    "Therefor, you need to provide Jina some sort of evaluation metric.\n",
    "In the pokemon dataset, there are two edition with the same pokemon, but different images: `red-blue` and `red-green`.\n",
    "\n",
    "![1.png](attachment:cb8f8cf6-92f7-4b7f-9a75-43029261979b.png)![1.png](attachment:1a98c688-569b-4b08-aa1d-3dbb7fadd38f.png)\n",
    "\n",
    "Thus, we will setup the following evaluation metric:\n",
    "Index one edition and search with the other edition.\n",
    "We have a success, if the right pokemon is at the first place in the search results.\n",
    "\n",
    "We need to do the following steps:\n",
    "\n",
    "- A) build an `index` and a `search` Flow, which are repeaditly runnable\n",
    "- B) use the `red-blue` dataset for `index` and the `red-green` for `search`\n",
    "- C) implement an `EvaluationCallback` which will calculate, if the right pokemon is in the first place\n",
    "- D) set the needed `OptimizationParameter` via a `parameter.yml` file\n",
    "- E) setup the optimization process itself\n",
    "\n",
    "**NOTE**: Under the hood, we use [optuna](https://optuna.readthedocs.io/en/stable/) for hyperparameter optimization.\n",
    "\n",
    "### Do the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from jina import Document\n",
    "from jina.optimizers.flow_runner import SingleFlowRunner, MultiFlowRunner\n",
    "from jina.optimizers import FlowOptimizer, MeanEvaluationCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-fossil",
   "metadata": {},
   "source": [
    "### A) & B)\n",
    "\n",
    "Jina provides the \n",
    "- `SingleFlowRunner` for making a Flow repeaditly runnable and the \n",
    "- `MultiFlowRunner` to chain multiple `SingleFlowRunner` for the `FlowOptimizer`\n",
    "\n",
    "For setup you need:\n",
    "- `flow_yaml`: the definition of a Flow\n",
    "- `documents`: the Documents, which are send to the Flow in each optimization step\n",
    "- `execution_method`: tell the Flow, whether `index` or `search` should be used\n",
    "\n",
    "Beware, that we introduce `JINA_MODEL_NAME_VAR: ${{JINA_MODEL_NAME}}` in the two new Flow definition.\n",
    "This variable will allow us to change the model in the Flow in each optimization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_iterator(edition, full_document):\n",
    "    image_src = f'data/pokemon/main-sprites/{edition}/*.png'\n",
    "    for filename in glob.iglob(image_src, recursive=True):\n",
    "        if full_document:\n",
    "            with open(filename, 'rb') as fp:\n",
    "                yield Document(buffer=fp.read(), tags={'filename': filename})\n",
    "        else:\n",
    "            yield filename\n",
    "\n",
    "def get_flows():\n",
    "    index_flow = SingleFlowRunner(\n",
    "        flow_yaml='flows/index_opt.yml',\n",
    "        documents=get_input_iterator('red-blue', True),\n",
    "        request_size=64,\n",
    "        execution_method='index',\n",
    "        overwrite_workspace=True\n",
    "    )\n",
    "\n",
    "    search_flow = SingleFlowRunner(\n",
    "        flow_yaml='flows/query_opt.yml',\n",
    "        documents=get_input_iterator('red-green', False),\n",
    "        request_size=64,\n",
    "        execution_method='search'\n",
    "    )\n",
    "\n",
    "    multi_flow = MultiFlowRunner([index_flow, search_flow])\n",
    "    return multi_flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-database",
   "metadata": {},
   "source": [
    "### C) implement an `EvaluationCallback` which will calculate, if the right pokemon is in the first place\n",
    "\n",
    "Since the files are named the same for both editions, we use the filename as an identifier, whether we found the right pokemon.\n",
    "The `PokemonCallback` checks for each Document, whether the correct result is in the first position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(filename):\n",
    "    return filename.split('/')[-1].split('.')[0]\n",
    "\n",
    "class PokemonCallback(MeanEvaluationCallback):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._eval_name = \"pokedex_eval\"\n",
    "\n",
    "    def get_empty_copy(self):\n",
    "        return PokemonCallback(self._eval_name)\n",
    "    \n",
    "    def __call__(self, response):\n",
    "        self._n_docs += len(response.search.docs)\n",
    "        for doc in response.search.docs:\n",
    "            if doc.matches:\n",
    "                document_id = get_id(doc.uri)\n",
    "                first_match_id = get_id(str(doc.matches[0].tags.fields['filename']))\n",
    "                if document_id == first_match_id:\n",
    "                    self._evaluation_values[self._eval_name] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-dispatch",
   "metadata": {},
   "source": [
    "### D) set the needed `OptimizationParameter` via a `parameter.yml` file\n",
    "\n",
    "We defined in the `parameter_few.yml` the models, that the optimizer should try out.\n",
    "For demonstation purpose, we just added three models, in order to make the optimizer run rather short.\n",
    "If you want to try mode models, please use the `parameter.yml` file and increase `n_trials` parameter in the `FlowOptimizer` below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-brooklyn",
   "metadata": {},
   "source": [
    "### E) setup the optimization process itself\n",
    "\n",
    "Finally, we build the `FlowOptimizer` object.\n",
    "It needs:\n",
    "- `flow_runner`: the repeaditly runnable Flow object\n",
    "- `parameter_yaml`: the parameters which the optimizer can change\n",
    "- `evaluation_callback`: our previously defined evaluation function\n",
    "- `workspace_base_dir`: A directory for temporary data\n",
    "- `n_trials`: The amount of optimization steps, that should be performed\n",
    "- `sampler`: the way, the `FlowOptimizer` should sample new values in each step. For more info please look at the [optuna docs](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.samplers.RandomSampler.html#optuna.samplers.RandomSampler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-looking",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def optimize(flows):\n",
    "    optimizer = FlowOptimizer(\n",
    "        flow_runner=flows,\n",
    "        parameter_yaml='optimize/parameters_few.yml',\n",
    "        evaluation_callback=PokemonCallback(eval_name='correct'),\n",
    "        workspace_base_dir='workspace',\n",
    "        n_trials=3,\n",
    "        sampler='RandomSampler'\n",
    "    )\n",
    "    result = optimizer.optimize_flow()\n",
    "    result.save_parameters('optimize/best_config.yml')\n",
    "\n",
    "flows = get_flows()\n",
    "optimize(flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-student",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
